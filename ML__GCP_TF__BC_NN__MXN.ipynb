{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (ML): Google Cloud Platform (GCP): TensorFlow (TF): Financial Time-Series\n",
    "# Model 01 = Binary Classifier\n",
    "# Model 02 = Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gcp\n",
    "import gcp.bigquery as bq\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Install stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading/unpacking xlrd\n",
      "  Downloading xlrd-1.0.0.tar.gz (2.6MB): 2.6MB downloaded\n",
      "  Running setup.py (path:/tmp/pip-build-A5MTxa/xlrd/setup.py) egg_info for package xlrd\n",
      "    \n",
      "    warning: no files found matching 'README.html'\n",
      "Installing collected packages: xlrd\n",
      "  Running setup.py install for xlrd\n",
      "    changing mode of build/scripts-2.7/runxlrd.py from 644 to 755\n",
      "    \n",
      "    warning: no files found matching 'README.html'\n",
      "    changing mode of /usr/local/bin/runxlrd.py to 755\n",
      "\u001b[33m  Could not find .egg-info directory in install record for xlrd\n",
      "\u001b[0mSuccessfully installed xlrd\n",
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "# Install xlrd\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Get the data from dropbox excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save file on dropbox.com\n",
    "# Right click to get the link\n",
    "force = 1\n",
    "\n",
    "# url_data_raw = 'https://www.dropbox.com/s/t8egr3lqxlpzcj8/data_raw.xlsm' # (dropbox for wylie.chan@gmail.com)\n",
    "# url_data_raw = 'https://www.dropbox.com/s/9hlf1lrmqfy093v/data_raw.xlsm' #  (dropbox for eyup.saltik.2016@gmail.com)  \n",
    "url_data_raw = 'https://www.dropbox.com/s/hwkuunzjvj9vph5/data_raw_03.xlsm' # updated 2016/07/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_raw_03.xlsm\n",
      "converted 'https://www.dropbox.com/s/hwkuunzjvj9vph5/data_raw_03.xlsm' (ANSI_X3.4-1968) -> 'https://www.dropbox.com/s/hwkuunzjvj9vph5/data_raw_03.xlsm' (UTF-8)\n",
      "--2016-07-26 01:32:18--  https://www.dropbox.com/s/hwkuunzjvj9vph5/data_raw_03.xlsm\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 108.160.172.206\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|108.160.172.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://dl.dropboxusercontent.com/content_link/zUSZ8lTiOPfTbnjFUmtL1N3V69kiBOroyvu0ZXhOzxS2yVGMcWrYzL5BMLMVjkQj/file [following]\n",
      "converted 'https://dl.dropboxusercontent.com/content_link/zUSZ8lTiOPfTbnjFUmtL1N3V69kiBOroyvu0ZXhOzxS2yVGMcWrYzL5BMLMVjkQj/file' (ANSI_X3.4-1968) -> 'https://dl.dropboxusercontent.com/content_link/zUSZ8lTiOPfTbnjFUmtL1N3V69kiBOroyvu0ZXhOzxS2yVGMcWrYzL5BMLMVjkQj/file' (UTF-8)\n",
      "--2016-07-26 01:32:20--  https://dl.dropboxusercontent.com/content_link/zUSZ8lTiOPfTbnjFUmtL1N3V69kiBOroyvu0ZXhOzxS2yVGMcWrYzL5BMLMVjkQj/file\n",
      "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 45.58.75.133\n",
      "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|45.58.75.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2807027 (2.7M) [application/vnd.ms-excel.sheet.macroEnabled.12]\n",
      "Saving to: 'data_raw_03.xlsm'\n",
      "\n",
      "data_raw_03.xlsm    100%[=====================>]   2.68M  12.0MB/s   in 0.2s   \n",
      "\n",
      "2016-07-26 01:32:20 (12.0 MB/s) - 'data_raw_03.xlsm' saved [2807027/2807027]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import file using url to file on dropbox\n",
    "from urlparse import urlparse\n",
    "from os.path import basename\n",
    "\n",
    "bn_data_raw = basename(urlparse(url_data_raw).path)\n",
    "print bn_data_raw\n",
    "\n",
    "try:\n",
    "    already_downloaded\n",
    "except:\n",
    "    already_downloaded = False\n",
    "    \n",
    "if force or not already_downloaded:\n",
    "    already_downloaded = True\n",
    "    !rm $bn_data_raw\n",
    "    !wget $url_data_raw\n",
    "#!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Read the Excel file raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-27 00:00:00</td>\n",
       "      <td>18.4751</td>\n",
       "      <td>289.95</td>\n",
       "      <td>55.4</td>\n",
       "      <td>141.28</td>\n",
       "      <td>424.14</td>\n",
       "      <td>111.85</td>\n",
       "      <td>118.813</td>\n",
       "      <td>66.0342</td>\n",
       "      <td>35645.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.138</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-18</td>\n",
       "      <td>-31.63</td>\n",
       "      <td>1.943</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.133</td>\n",
       "      <td>2.1738</td>\n",
       "      <td>124.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-26 00:00:00</td>\n",
       "      <td>18.4544</td>\n",
       "      <td>284.68</td>\n",
       "      <td>55.29</td>\n",
       "      <td>141.83</td>\n",
       "      <td>427.999</td>\n",
       "      <td>111.845</td>\n",
       "      <td>118.75</td>\n",
       "      <td>65.282</td>\n",
       "      <td>35316.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.139</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>-31.43</td>\n",
       "      <td>1.928</td>\n",
       "      <td>2.0575</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.1598</td>\n",
       "      <td>124.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-25 00:00:00</td>\n",
       "      <td>18.4852</td>\n",
       "      <td>281.4</td>\n",
       "      <td>56.33</td>\n",
       "      <td>140.98</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.825</td>\n",
       "      <td>118.438</td>\n",
       "      <td>65.9242</td>\n",
       "      <td>35680.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>1.955</td>\n",
       "      <td>2.0825</td>\n",
       "      <td>2.1453</td>\n",
       "      <td>2.1785</td>\n",
       "      <td>124.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0              1                2                 3   \\\n",
       "0               Ticker  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity   \n",
       "1                 Date  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity   \n",
       "2  2016-05-27 00:00:00        18.4751           289.95              55.4   \n",
       "3  2016-05-26 00:00:00        18.4544           284.68             55.29   \n",
       "4  2016-05-25 00:00:00        18.4852            281.4             56.33   \n",
       "\n",
       "           4                5           6                   7   \\\n",
       "0  CN1 Comdty  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp   \n",
       "1  CN1 Comdty  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp   \n",
       "2      141.28           424.14      111.85             118.813   \n",
       "3      141.83          427.999     111.845              118.75   \n",
       "4      140.98          5392.86     111.825             118.438   \n",
       "\n",
       "               8                9      ...                      77  \\\n",
       "0  EMRUEMRU Index  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy   \n",
       "1  EMRUEMRU Index  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy   \n",
       "2         66.0342          35645.2     ...                   2.102   \n",
       "3          65.282          35316.9     ...                   2.104   \n",
       "4         65.9242          35680.2     ...                   2.107   \n",
       "\n",
       "                   78                  79                  80  \\\n",
       "0  USSA30 ICPL Curncy  USSP15 CMPN Curncy  USSP20 CMPN Curncy   \n",
       "1  USSA30 ICPL Curncy  USSP15 CMPN Curncy  USSP20 CMPN Curncy   \n",
       "2               2.138              -10.63                 -18   \n",
       "3               2.139              -10.46              -17.65   \n",
       "4                2.14              -11.11               -18.4   \n",
       "\n",
       "                   81                  82                  83  \\\n",
       "0  USSP25 CMPN Curncy  USSW15 CMPN Curncy  USSW20 CMPN Curncy   \n",
       "1  USSP25 CMPN Curncy  USSW15 CMPN Curncy  USSW20 CMPN Curncy   \n",
       "2              -31.63               1.943               2.074   \n",
       "3              -31.43               1.928              2.0575   \n",
       "4              -32.03               1.955              2.0825   \n",
       "\n",
       "                   84                  85          86  \n",
       "0  USSW25 CMPN Curncy  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "1  USSW25 CMPN Curncy  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "2               2.133              2.1738      124.13  \n",
       "3               2.125              2.1598       124.3  \n",
       "4              2.1453              2.1785      124.11  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "# Read the excel data\n",
    "data_raw = pd.read_excel(bn_data_raw, 'data_raw')\n",
    "# data = pd.read_excel(bn_data_raw, 'data_raw', header=0, index_col=0, parse_cols=None)\n",
    "  # parse_cols=None: parse all columns\n",
    "  # header=0:    sets the row 0 as col labels (ie. headers)\n",
    "  # index_col=0: sets the col 0 as row labels (ie. index)\n",
    "data_raw.head() # display the first few lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Skip: Select only the columns that we have chosen from the PCA50 exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-27 00:00:00</td>\n",
       "      <td>18.4751</td>\n",
       "      <td>289.95</td>\n",
       "      <td>55.4</td>\n",
       "      <td>141.28</td>\n",
       "      <td>424.14</td>\n",
       "      <td>111.85</td>\n",
       "      <td>118.813</td>\n",
       "      <td>66.0342</td>\n",
       "      <td>35645.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.138</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-18</td>\n",
       "      <td>-31.63</td>\n",
       "      <td>1.943</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.133</td>\n",
       "      <td>2.1738</td>\n",
       "      <td>124.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-26 00:00:00</td>\n",
       "      <td>18.4544</td>\n",
       "      <td>284.68</td>\n",
       "      <td>55.29</td>\n",
       "      <td>141.83</td>\n",
       "      <td>427.999</td>\n",
       "      <td>111.845</td>\n",
       "      <td>118.75</td>\n",
       "      <td>65.282</td>\n",
       "      <td>35316.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.139</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>-31.43</td>\n",
       "      <td>1.928</td>\n",
       "      <td>2.0575</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.1598</td>\n",
       "      <td>124.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-25 00:00:00</td>\n",
       "      <td>18.4852</td>\n",
       "      <td>281.4</td>\n",
       "      <td>56.33</td>\n",
       "      <td>140.98</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.825</td>\n",
       "      <td>118.438</td>\n",
       "      <td>65.9242</td>\n",
       "      <td>35680.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>1.955</td>\n",
       "      <td>2.0825</td>\n",
       "      <td>2.1453</td>\n",
       "      <td>2.1785</td>\n",
       "      <td>124.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0              1                2                 3   \\\n",
       "0               Ticker  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity   \n",
       "1                 Date  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity   \n",
       "2  2016-05-27 00:00:00        18.4751           289.95              55.4   \n",
       "3  2016-05-26 00:00:00        18.4544           284.68             55.29   \n",
       "4  2016-05-25 00:00:00        18.4852            281.4             56.33   \n",
       "\n",
       "           4                5           6                   7   \\\n",
       "0  CN1 Comdty  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp   \n",
       "1  CN1 Comdty  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp   \n",
       "2      141.28           424.14      111.85             118.813   \n",
       "3      141.83          427.999     111.845              118.75   \n",
       "4      140.98          5392.86     111.825             118.438   \n",
       "\n",
       "               8                9      ...                      77  \\\n",
       "0  EMRUEMRU Index  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy   \n",
       "1  EMRUEMRU Index  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy   \n",
       "2         66.0342          35645.2     ...                   2.102   \n",
       "3          65.282          35316.9     ...                   2.104   \n",
       "4         65.9242          35680.2     ...                   2.107   \n",
       "\n",
       "                   78                  79                  80  \\\n",
       "0  USSA30 ICPL Curncy  USSP15 CMPN Curncy  USSP20 CMPN Curncy   \n",
       "1  USSA30 ICPL Curncy  USSP15 CMPN Curncy  USSP20 CMPN Curncy   \n",
       "2               2.138              -10.63                 -18   \n",
       "3               2.139              -10.46              -17.65   \n",
       "4                2.14              -11.11               -18.4   \n",
       "\n",
       "                   81                  82                  83  \\\n",
       "0  USSP25 CMPN Curncy  USSW15 CMPN Curncy  USSW20 CMPN Curncy   \n",
       "1  USSP25 CMPN Curncy  USSW15 CMPN Curncy  USSW20 CMPN Curncy   \n",
       "2              -31.63               1.943               2.074   \n",
       "3              -31.43               1.928              2.0575   \n",
       "4              -32.03               1.955              2.0825   \n",
       "\n",
       "                   84                  85          86  \n",
       "0  USSW25 CMPN Curncy  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "1  USSW25 CMPN Curncy  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "2               2.133              2.1738      124.13  \n",
       "3               2.125              2.1598       124.3  \n",
       "4              2.1453              2.1785      124.11  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This list pertains to first set of data.\n",
    "# list_cols_pca = [ 0,1,\n",
    "#                   1070,788,926,112,69,574,654,1160,527,323,\n",
    "#                   397,118,774,1028,1034,655,907,736,251,388,\n",
    "#                   327,243,705,303,1146,467,136,1006,600,15,\n",
    "#                   231,290,131,782,20,1048,630,1173,431,856,\n",
    "#                   67,299,838,639,53,932,870,938,1061\n",
    "#                 ]\n",
    "# data_raw_pca = data_raw[list_cols_pca]\n",
    "\n",
    "# For our new data set, we take all 86 columns\n",
    "data_raw_pca = data_raw\n",
    "data_raw_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) data_ticker_desc = Just a table to map column id to the ticker and name of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>USDMXN Curncy</td>\n",
       "      <td>ASURB MM Equity</td>\n",
       "      <td>BIMBOA MM Equity</td>\n",
       "      <td>CN1 Comdty</td>\n",
       "      <td>CT350188 Curncy</td>\n",
       "      <td>DU1 Comdty</td>\n",
       "      <td>ED749713@BVAL Corp</td>\n",
       "      <td>EMRUEMRU Index</td>\n",
       "      <td>EURMXN3Y Curncy</td>\n",
       "      <td>...</td>\n",
       "      <td>USSA25 ICPL Curncy</td>\n",
       "      <td>USSA30 ICPL Curncy</td>\n",
       "      <td>USSP15 CMPN Curncy</td>\n",
       "      <td>USSP20 CMPN Curncy</td>\n",
       "      <td>USSP25 CMPN Curncy</td>\n",
       "      <td>USSW15 CMPN Curncy</td>\n",
       "      <td>USSW20 CMPN Curncy</td>\n",
       "      <td>USSW25 CMPN Curncy</td>\n",
       "      <td>USSW30 CMPN Curncy</td>\n",
       "      <td>XQ1 Comdty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0              1                2                 3           4   \\\n",
       "0  Ticker  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity  CN1 Comdty   \n",
       "1    Date  USDMXN Curncy  ASURB MM Equity  BIMBOA MM Equity  CN1 Comdty   \n",
       "\n",
       "                5           6                   7               8   \\\n",
       "0  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp  EMRUEMRU Index   \n",
       "1  CT350188 Curncy  DU1 Comdty  ED749713@BVAL Corp  EMRUEMRU Index   \n",
       "\n",
       "                9      ...                      77                  78  \\\n",
       "0  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy  USSA30 ICPL Curncy   \n",
       "1  EURMXN3Y Curncy     ...      USSA25 ICPL Curncy  USSA30 ICPL Curncy   \n",
       "\n",
       "                   79                  80                  81  \\\n",
       "0  USSP15 CMPN Curncy  USSP20 CMPN Curncy  USSP25 CMPN Curncy   \n",
       "1  USSP15 CMPN Curncy  USSP20 CMPN Curncy  USSP25 CMPN Curncy   \n",
       "\n",
       "                   82                  83                  84  \\\n",
       "0  USSW15 CMPN Curncy  USSW20 CMPN Curncy  USSW25 CMPN Curncy   \n",
       "1  USSW15 CMPN Curncy  USSW20 CMPN Curncy  USSW25 CMPN Curncy   \n",
       "\n",
       "                   85          86  \n",
       "0  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "1  USSW30 CMPN Curncy  XQ1 Comdty  \n",
       "\n",
       "[2 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ticker_desc = data_raw_pca.ix[:1] # 1st 2 rows\n",
    "data_ticker_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) data_values = the actual values of the 86 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-27 00:00:00</td>\n",
       "      <td>18.4751</td>\n",
       "      <td>289.95</td>\n",
       "      <td>55.4</td>\n",
       "      <td>141.28</td>\n",
       "      <td>424.14</td>\n",
       "      <td>111.85</td>\n",
       "      <td>118.813</td>\n",
       "      <td>66.0342</td>\n",
       "      <td>35645.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.138</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-18</td>\n",
       "      <td>-31.63</td>\n",
       "      <td>1.943</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.133</td>\n",
       "      <td>2.1738</td>\n",
       "      <td>124.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-26 00:00:00</td>\n",
       "      <td>18.4544</td>\n",
       "      <td>284.68</td>\n",
       "      <td>55.29</td>\n",
       "      <td>141.83</td>\n",
       "      <td>427.999</td>\n",
       "      <td>111.845</td>\n",
       "      <td>118.75</td>\n",
       "      <td>65.282</td>\n",
       "      <td>35316.9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.139</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>-31.43</td>\n",
       "      <td>1.928</td>\n",
       "      <td>2.0575</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.1598</td>\n",
       "      <td>124.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-25 00:00:00</td>\n",
       "      <td>18.4852</td>\n",
       "      <td>281.4</td>\n",
       "      <td>56.33</td>\n",
       "      <td>140.98</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.825</td>\n",
       "      <td>118.438</td>\n",
       "      <td>65.9242</td>\n",
       "      <td>35680.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>1.955</td>\n",
       "      <td>2.0825</td>\n",
       "      <td>2.1453</td>\n",
       "      <td>2.1785</td>\n",
       "      <td>124.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-05-24 00:00:00</td>\n",
       "      <td>18.487</td>\n",
       "      <td>282.81</td>\n",
       "      <td>56.06</td>\n",
       "      <td>141.16</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.815</td>\n",
       "      <td>118.5</td>\n",
       "      <td>66.8658</td>\n",
       "      <td>36154.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126</td>\n",
       "      <td>2.158</td>\n",
       "      <td>-11.18</td>\n",
       "      <td>-18.43</td>\n",
       "      <td>-31.94</td>\n",
       "      <td>1.9469</td>\n",
       "      <td>2.0703</td>\n",
       "      <td>2.1305</td>\n",
       "      <td>2.1615</td>\n",
       "      <td>124.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-05-23 00:00:00</td>\n",
       "      <td>18.5161</td>\n",
       "      <td>282.02</td>\n",
       "      <td>55.27</td>\n",
       "      <td>141.31</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.815</td>\n",
       "      <td>120.188</td>\n",
       "      <td>67.0104</td>\n",
       "      <td>36684.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.092</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-10.81</td>\n",
       "      <td>-18.14</td>\n",
       "      <td>-31.55</td>\n",
       "      <td>1.9245</td>\n",
       "      <td>2.0503</td>\n",
       "      <td>2.112</td>\n",
       "      <td>2.1435</td>\n",
       "      <td>124.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1       2      3       4        5        6   \\\n",
       "2  2016-05-27 00:00:00  18.4751  289.95   55.4  141.28   424.14   111.85   \n",
       "3  2016-05-26 00:00:00  18.4544  284.68  55.29  141.83  427.999  111.845   \n",
       "4  2016-05-25 00:00:00  18.4852   281.4  56.33  140.98  5392.86  111.825   \n",
       "5  2016-05-24 00:00:00   18.487  282.81  56.06  141.16  5392.86  111.815   \n",
       "6  2016-05-23 00:00:00  18.5161  282.02  55.27  141.31  5392.86  111.815   \n",
       "\n",
       "        7        8        9    ...       77     78     79     80     81  \\\n",
       "2  118.813  66.0342  35645.2   ...    2.102  2.138 -10.63    -18 -31.63   \n",
       "3   118.75   65.282  35316.9   ...    2.104  2.139 -10.46 -17.65 -31.43   \n",
       "4  118.438  65.9242  35680.2   ...    2.107   2.14 -11.11  -18.4 -32.03   \n",
       "5    118.5  66.8658  36154.1   ...    2.126  2.158 -11.18 -18.43 -31.94   \n",
       "6  120.188  67.0104  36684.3   ...    2.092  2.125 -10.81 -18.14 -31.55   \n",
       "\n",
       "       82      83      84      85      86  \n",
       "2   1.943   2.074   2.133  2.1738  124.13  \n",
       "3   1.928  2.0575   2.125  2.1598   124.3  \n",
       "4   1.955  2.0825  2.1453  2.1785  124.11  \n",
       "5  1.9469  2.0703  2.1305  2.1615  124.24  \n",
       "6  1.9245  2.0503   2.112  2.1435  124.27  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values = data_raw_pca.ix[2:] # From row 2 onwards\n",
    "data_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Set the dates as index of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-27</th>\n",
       "      <td>18.4751</td>\n",
       "      <td>289.95</td>\n",
       "      <td>55.4</td>\n",
       "      <td>141.28</td>\n",
       "      <td>424.14</td>\n",
       "      <td>111.85</td>\n",
       "      <td>118.813</td>\n",
       "      <td>66.0342</td>\n",
       "      <td>35645.2</td>\n",
       "      <td>161.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.138</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-18</td>\n",
       "      <td>-31.63</td>\n",
       "      <td>1.943</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.133</td>\n",
       "      <td>2.1738</td>\n",
       "      <td>124.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-26</th>\n",
       "      <td>18.4544</td>\n",
       "      <td>284.68</td>\n",
       "      <td>55.29</td>\n",
       "      <td>141.83</td>\n",
       "      <td>427.999</td>\n",
       "      <td>111.845</td>\n",
       "      <td>118.75</td>\n",
       "      <td>65.282</td>\n",
       "      <td>35316.9</td>\n",
       "      <td>161.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.139</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>-31.43</td>\n",
       "      <td>1.928</td>\n",
       "      <td>2.0575</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.1598</td>\n",
       "      <td>124.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-25</th>\n",
       "      <td>18.4852</td>\n",
       "      <td>281.4</td>\n",
       "      <td>56.33</td>\n",
       "      <td>140.98</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.825</td>\n",
       "      <td>118.438</td>\n",
       "      <td>65.9242</td>\n",
       "      <td>35680.2</td>\n",
       "      <td>161.61</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>1.955</td>\n",
       "      <td>2.0825</td>\n",
       "      <td>2.1453</td>\n",
       "      <td>2.1785</td>\n",
       "      <td>124.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-24</th>\n",
       "      <td>18.487</td>\n",
       "      <td>282.81</td>\n",
       "      <td>56.06</td>\n",
       "      <td>141.16</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.815</td>\n",
       "      <td>118.5</td>\n",
       "      <td>66.8658</td>\n",
       "      <td>36154.1</td>\n",
       "      <td>161.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126</td>\n",
       "      <td>2.158</td>\n",
       "      <td>-11.18</td>\n",
       "      <td>-18.43</td>\n",
       "      <td>-31.94</td>\n",
       "      <td>1.9469</td>\n",
       "      <td>2.0703</td>\n",
       "      <td>2.1305</td>\n",
       "      <td>2.1615</td>\n",
       "      <td>124.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-23</th>\n",
       "      <td>18.5161</td>\n",
       "      <td>282.02</td>\n",
       "      <td>55.27</td>\n",
       "      <td>141.31</td>\n",
       "      <td>5392.86</td>\n",
       "      <td>111.815</td>\n",
       "      <td>120.188</td>\n",
       "      <td>67.0104</td>\n",
       "      <td>36684.3</td>\n",
       "      <td>161.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2.092</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-10.81</td>\n",
       "      <td>-18.14</td>\n",
       "      <td>-31.55</td>\n",
       "      <td>1.9245</td>\n",
       "      <td>2.0503</td>\n",
       "      <td>2.112</td>\n",
       "      <td>2.1435</td>\n",
       "      <td>124.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1       2      3       4        5        6        7   \\\n",
       "0                                                                       \n",
       "2016-05-27  18.4751  289.95   55.4  141.28   424.14   111.85  118.813   \n",
       "2016-05-26  18.4544  284.68  55.29  141.83  427.999  111.845   118.75   \n",
       "2016-05-25  18.4852   281.4  56.33  140.98  5392.86  111.825  118.438   \n",
       "2016-05-24   18.487  282.81  56.06  141.16  5392.86  111.815    118.5   \n",
       "2016-05-23  18.5161  282.02  55.27  141.31  5392.86  111.815  120.188   \n",
       "\n",
       "                 8        9       10   ...       77     78     79     80  \\\n",
       "0                                      ...                                 \n",
       "2016-05-27  66.0342  35645.2  161.89   ...    2.102  2.138 -10.63    -18   \n",
       "2016-05-26   65.282  35316.9   161.8   ...    2.104  2.139 -10.46 -17.65   \n",
       "2016-05-25  65.9242  35680.2  161.61   ...    2.107   2.14 -11.11  -18.4   \n",
       "2016-05-24  66.8658  36154.1  161.58   ...    2.126  2.158 -11.18 -18.43   \n",
       "2016-05-23  67.0104  36684.3  161.55   ...    2.092  2.125 -10.81 -18.14   \n",
       "\n",
       "               81      82      83      84      85      86  \n",
       "0                                                          \n",
       "2016-05-27 -31.63   1.943   2.074   2.133  2.1738  124.13  \n",
       "2016-05-26 -31.43   1.928  2.0575   2.125  2.1598   124.3  \n",
       "2016-05-25 -32.03   1.955  2.0825  2.1453  2.1785  124.11  \n",
       "2016-05-24 -31.94  1.9469  2.0703  2.1305  2.1615  124.24  \n",
       "2016-05-23 -31.55  1.9245  2.0503   2.112  2.1435  124.27  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed = data_values.set_index([0])\n",
    "data_values_indexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>9.565</td>\n",
       "      <td>14.23</td>\n",
       "      <td>4.83</td>\n",
       "      <td>117.45</td>\n",
       "      <td>382.997</td>\n",
       "      <td>102.71</td>\n",
       "      <td>132.35</td>\n",
       "      <td>27.321</td>\n",
       "      <td>22485</td>\n",
       "      <td>119.16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.475</td>\n",
       "      <td>7.465</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.461</td>\n",
       "      <td>7.4</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>9.58</td>\n",
       "      <td>14.23</td>\n",
       "      <td>4.68</td>\n",
       "      <td>117.09</td>\n",
       "      <td>382.997</td>\n",
       "      <td>102.5</td>\n",
       "      <td>132.35</td>\n",
       "      <td>27.321</td>\n",
       "      <td>22485</td>\n",
       "      <td>118.7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.505</td>\n",
       "      <td>7.48</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.461</td>\n",
       "      <td>7.43</td>\n",
       "      <td>97.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>9.571</td>\n",
       "      <td>14.23</td>\n",
       "      <td>4.83</td>\n",
       "      <td>116.57</td>\n",
       "      <td>382.997</td>\n",
       "      <td>102.49</td>\n",
       "      <td>132.35</td>\n",
       "      <td>27.321</td>\n",
       "      <td>22485</td>\n",
       "      <td>119.15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.475</td>\n",
       "      <td>7.455</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.48</td>\n",
       "      <td>6.461</td>\n",
       "      <td>7.46</td>\n",
       "      <td>97.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>9.5713</td>\n",
       "      <td>14.23</td>\n",
       "      <td>4.83</td>\n",
       "      <td>117.5</td>\n",
       "      <td>382.997</td>\n",
       "      <td>102.49</td>\n",
       "      <td>132.35</td>\n",
       "      <td>27.54</td>\n",
       "      <td>22485</td>\n",
       "      <td>119.2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.425</td>\n",
       "      <td>7.425</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.461</td>\n",
       "      <td>7.4</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>9.505</td>\n",
       "      <td>14.23</td>\n",
       "      <td>5.03</td>\n",
       "      <td>118.5</td>\n",
       "      <td>382.997</td>\n",
       "      <td>102.47</td>\n",
       "      <td>132.35</td>\n",
       "      <td>27.54</td>\n",
       "      <td>22485</td>\n",
       "      <td>119.85</td>\n",
       "      <td>...</td>\n",
       "      <td>7.455</td>\n",
       "      <td>7.425</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>7.46</td>\n",
       "      <td>7.47</td>\n",
       "      <td>6.461</td>\n",
       "      <td>7.44</td>\n",
       "      <td>98.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1      2     3       4        5       6       7       8   \\\n",
       "0                                                                          \n",
       "2000-01-07   9.565  14.23  4.83  117.45  382.997  102.71  132.35  27.321   \n",
       "2000-01-06    9.58  14.23  4.68  117.09  382.997   102.5  132.35  27.321   \n",
       "2000-01-05   9.571  14.23  4.83  116.57  382.997  102.49  132.35  27.321   \n",
       "2000-01-04  9.5713  14.23  4.83   117.5  382.997  102.49  132.35   27.54   \n",
       "2000-01-03   9.505  14.23  5.03   118.5  382.997  102.47  132.35   27.54   \n",
       "\n",
       "               9       10  ...       77     78  79  80  81    82    83     84  \\\n",
       "0                          ...                                                  \n",
       "2000-01-07  22485  119.16  ...    7.475  7.465  87  89  84  7.39  7.41  6.461   \n",
       "2000-01-06  22485   118.7  ...    7.505   7.48  89  90  84  7.43  7.44  6.461   \n",
       "2000-01-05  22485  119.15  ...    7.475  7.455  88  89  84  7.47  7.48  6.461   \n",
       "2000-01-04  22485   119.2  ...    7.425  7.425  90  91  84   7.4  7.41  6.461   \n",
       "2000-01-03  22485  119.85  ...    7.455  7.425  86  87  84  7.46  7.47  6.461   \n",
       "\n",
       "              85     86  \n",
       "0                        \n",
       "2000-01-07   7.4     98  \n",
       "2000-01-06  7.43   97.7  \n",
       "2000-01-05  7.46  97.55  \n",
       "2000-01-04   7.4     98  \n",
       "2000-01-03  7.44  98.56  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Fill any gaps in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-27</th>\n",
       "      <td>18.4751</td>\n",
       "      <td>289.95</td>\n",
       "      <td>55.40</td>\n",
       "      <td>141.28</td>\n",
       "      <td>424.140</td>\n",
       "      <td>111.850</td>\n",
       "      <td>118.813</td>\n",
       "      <td>66.0342</td>\n",
       "      <td>35645.2148</td>\n",
       "      <td>161.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2.102</td>\n",
       "      <td>2.138</td>\n",
       "      <td>-10.63</td>\n",
       "      <td>-18.00</td>\n",
       "      <td>-31.63</td>\n",
       "      <td>1.9430</td>\n",
       "      <td>2.0740</td>\n",
       "      <td>2.1330</td>\n",
       "      <td>2.1738</td>\n",
       "      <td>124.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-26</th>\n",
       "      <td>18.4544</td>\n",
       "      <td>284.68</td>\n",
       "      <td>55.29</td>\n",
       "      <td>141.83</td>\n",
       "      <td>427.999</td>\n",
       "      <td>111.845</td>\n",
       "      <td>118.750</td>\n",
       "      <td>65.2820</td>\n",
       "      <td>35316.8828</td>\n",
       "      <td>161.80</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104</td>\n",
       "      <td>2.139</td>\n",
       "      <td>-10.46</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>-31.43</td>\n",
       "      <td>1.9280</td>\n",
       "      <td>2.0575</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>2.1598</td>\n",
       "      <td>124.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-25</th>\n",
       "      <td>18.4852</td>\n",
       "      <td>281.40</td>\n",
       "      <td>56.33</td>\n",
       "      <td>140.98</td>\n",
       "      <td>5392.863</td>\n",
       "      <td>111.825</td>\n",
       "      <td>118.438</td>\n",
       "      <td>65.9242</td>\n",
       "      <td>35680.2227</td>\n",
       "      <td>161.61</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107</td>\n",
       "      <td>2.140</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-18.40</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>1.9550</td>\n",
       "      <td>2.0825</td>\n",
       "      <td>2.1453</td>\n",
       "      <td>2.1785</td>\n",
       "      <td>124.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-24</th>\n",
       "      <td>18.4870</td>\n",
       "      <td>282.81</td>\n",
       "      <td>56.06</td>\n",
       "      <td>141.16</td>\n",
       "      <td>5392.863</td>\n",
       "      <td>111.815</td>\n",
       "      <td>118.500</td>\n",
       "      <td>66.8658</td>\n",
       "      <td>36154.1172</td>\n",
       "      <td>161.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126</td>\n",
       "      <td>2.158</td>\n",
       "      <td>-11.18</td>\n",
       "      <td>-18.43</td>\n",
       "      <td>-31.94</td>\n",
       "      <td>1.9469</td>\n",
       "      <td>2.0703</td>\n",
       "      <td>2.1305</td>\n",
       "      <td>2.1615</td>\n",
       "      <td>124.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-23</th>\n",
       "      <td>18.5161</td>\n",
       "      <td>282.02</td>\n",
       "      <td>55.27</td>\n",
       "      <td>141.31</td>\n",
       "      <td>5392.863</td>\n",
       "      <td>111.815</td>\n",
       "      <td>120.188</td>\n",
       "      <td>67.0104</td>\n",
       "      <td>36684.3047</td>\n",
       "      <td>161.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2.092</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-10.81</td>\n",
       "      <td>-18.14</td>\n",
       "      <td>-31.55</td>\n",
       "      <td>1.9245</td>\n",
       "      <td>2.0503</td>\n",
       "      <td>2.1120</td>\n",
       "      <td>2.1435</td>\n",
       "      <td>124.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1       2      3       4         5        6        7   \\\n",
       "0                                                                        \n",
       "2016-05-27  18.4751  289.95  55.40  141.28   424.140  111.850  118.813   \n",
       "2016-05-26  18.4544  284.68  55.29  141.83   427.999  111.845  118.750   \n",
       "2016-05-25  18.4852  281.40  56.33  140.98  5392.863  111.825  118.438   \n",
       "2016-05-24  18.4870  282.81  56.06  141.16  5392.863  111.815  118.500   \n",
       "2016-05-23  18.5161  282.02  55.27  141.31  5392.863  111.815  120.188   \n",
       "\n",
       "                 8           9       10   ...       77     78     79     80  \\\n",
       "0                                         ...                                 \n",
       "2016-05-27  66.0342  35645.2148  161.89   ...    2.102  2.138 -10.63 -18.00   \n",
       "2016-05-26  65.2820  35316.8828  161.80   ...    2.104  2.139 -10.46 -17.65   \n",
       "2016-05-25  65.9242  35680.2227  161.61   ...    2.107  2.140 -11.11 -18.40   \n",
       "2016-05-24  66.8658  36154.1172  161.58   ...    2.126  2.158 -11.18 -18.43   \n",
       "2016-05-23  67.0104  36684.3047  161.55   ...    2.092  2.125 -10.81 -18.14   \n",
       "\n",
       "               81      82      83      84      85      86  \n",
       "0                                                          \n",
       "2016-05-27 -31.63  1.9430  2.0740  2.1330  2.1738  124.13  \n",
       "2016-05-26 -31.43  1.9280  2.0575  2.1250  2.1598  124.30  \n",
       "2016-05-25 -32.03  1.9550  2.0825  2.1453  2.1785  124.11  \n",
       "2016-05-24 -31.94  1.9469  2.0703  2.1305  2.1615  124.24  \n",
       "2016-05-23 -31.55  1.9245  2.0503  2.1120  2.1435  124.27  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas includes a very convenient function for filling gaps in the data.\n",
    "data_values_indexed = data_values_indexed.fillna(method='ffill')\n",
    "data_values_indexed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is foundational to working with machine learning, and any other sort of analysis. EDA means getting to know your data, getting your fingers dirty with your data, feeling it and seeing it. The end result is you know your data very well, so when you build models you build them based on an actual, practical, physical understanding of the data, not assumptions or vaguely held notions. You can still make assumptions of course, but EDA means you will understand your assumptions and why you're making those assumptions. \n",
    "\n",
    "First, take a look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Describe the data briefly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.911366</td>\n",
       "      <td>73.947745</td>\n",
       "      <td>18.881708</td>\n",
       "      <td>119.598056</td>\n",
       "      <td>1274.780457</td>\n",
       "      <td>106.901370</td>\n",
       "      <td>129.810225</td>\n",
       "      <td>32.755946</td>\n",
       "      <td>21444.728984</td>\n",
       "      <td>135.740386</td>\n",
       "      <td>...</td>\n",
       "      <td>4.514619</td>\n",
       "      <td>4.538804</td>\n",
       "      <td>52.535717</td>\n",
       "      <td>48.223883</td>\n",
       "      <td>33.826551</td>\n",
       "      <td>4.348641</td>\n",
       "      <td>4.476098</td>\n",
       "      <td>4.485189</td>\n",
       "      <td>4.547887</td>\n",
       "      <td>110.571528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.994357</td>\n",
       "      <td>68.242552</td>\n",
       "      <td>14.150547</td>\n",
       "      <td>12.524152</td>\n",
       "      <td>1459.830658</td>\n",
       "      <td>3.125247</td>\n",
       "      <td>6.684781</td>\n",
       "      <td>10.467811</td>\n",
       "      <td>4250.049262</td>\n",
       "      <td>13.389009</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388181</td>\n",
       "      <td>1.372625</td>\n",
       "      <td>30.698940</td>\n",
       "      <td>34.171762</td>\n",
       "      <td>34.130836</td>\n",
       "      <td>1.431227</td>\n",
       "      <td>1.400364</td>\n",
       "      <td>1.305526</td>\n",
       "      <td>1.362411</td>\n",
       "      <td>7.591973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.970000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>97.110000</td>\n",
       "      <td>182.532000</td>\n",
       "      <td>101.100000</td>\n",
       "      <td>92.985000</td>\n",
       "      <td>23.089000</td>\n",
       "      <td>9962.501200</td>\n",
       "      <td>114.210000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887000</td>\n",
       "      <td>1.928000</td>\n",
       "      <td>-13.840000</td>\n",
       "      <td>-26.250000</td>\n",
       "      <td>-37.500000</td>\n",
       "      <td>1.737800</td>\n",
       "      <td>1.863300</td>\n",
       "      <td>1.924300</td>\n",
       "      <td>1.960500</td>\n",
       "      <td>96.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.635750</td>\n",
       "      <td>21.275000</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>109.847500</td>\n",
       "      <td>382.997000</td>\n",
       "      <td>103.995000</td>\n",
       "      <td>128.298000</td>\n",
       "      <td>28.140375</td>\n",
       "      <td>18765.977525</td>\n",
       "      <td>126.027500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.274000</td>\n",
       "      <td>3.312750</td>\n",
       "      <td>28.690000</td>\n",
       "      <td>18.985000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.074000</td>\n",
       "      <td>3.236875</td>\n",
       "      <td>3.303000</td>\n",
       "      <td>3.337750</td>\n",
       "      <td>106.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.357750</td>\n",
       "      <td>51.995000</td>\n",
       "      <td>15.455000</td>\n",
       "      <td>117.300000</td>\n",
       "      <td>541.548000</td>\n",
       "      <td>106.467500</td>\n",
       "      <td>132.350000</td>\n",
       "      <td>29.795000</td>\n",
       "      <td>22347.502700</td>\n",
       "      <td>131.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.805000</td>\n",
       "      <td>4.822000</td>\n",
       "      <td>53.615000</td>\n",
       "      <td>54.730000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>4.633750</td>\n",
       "      <td>4.770500</td>\n",
       "      <td>4.815500</td>\n",
       "      <td>4.832500</td>\n",
       "      <td>106.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.057125</td>\n",
       "      <td>96.162500</td>\n",
       "      <td>29.980000</td>\n",
       "      <td>131.025000</td>\n",
       "      <td>1690.914000</td>\n",
       "      <td>110.320000</td>\n",
       "      <td>132.350000</td>\n",
       "      <td>31.731000</td>\n",
       "      <td>22485.002700</td>\n",
       "      <td>146.980000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.445000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>72.630000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>60.212500</td>\n",
       "      <td>5.309250</td>\n",
       "      <td>5.415125</td>\n",
       "      <td>5.448500</td>\n",
       "      <td>5.451125</td>\n",
       "      <td>117.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.147600</td>\n",
       "      <td>290.260000</td>\n",
       "      <td>57.020000</td>\n",
       "      <td>146.130000</td>\n",
       "      <td>6937.675000</td>\n",
       "      <td>111.950000</td>\n",
       "      <td>153.093000</td>\n",
       "      <td>84.856000</td>\n",
       "      <td>45139.001500</td>\n",
       "      <td>171.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>7.855000</td>\n",
       "      <td>146.010000</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>7.886000</td>\n",
       "      <td>7.863000</td>\n",
       "      <td>6.636000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>135.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1            2            3            4            5   \\\n",
       "count  4280.000000  4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean     11.911366    73.947745    18.881708   119.598056  1274.780457   \n",
       "std       1.994357    68.242552    14.150547    12.524152  1459.830658   \n",
       "min       8.970000     8.500000     2.840000    97.110000   182.532000   \n",
       "25%      10.635750    21.275000     5.760000   109.847500   382.997000   \n",
       "50%      11.357750    51.995000    15.455000   117.300000   541.548000   \n",
       "75%      13.057125    96.162500    29.980000   131.025000  1690.914000   \n",
       "max      19.147600   290.260000    57.020000   146.130000  6937.675000   \n",
       "\n",
       "                6            7            8             9            10  \\\n",
       "count  4280.000000  4280.000000  4280.000000   4280.000000  4280.000000   \n",
       "mean    106.901370   129.810225    32.755946  21444.728984   135.740386   \n",
       "std       3.125247     6.684781    10.467811   4250.049262    13.389009   \n",
       "min     101.100000    92.985000    23.089000   9962.501200   114.210000   \n",
       "25%     103.995000   128.298000    28.140375  18765.977525   126.027500   \n",
       "50%     106.467500   132.350000    29.795000  22347.502700   131.550000   \n",
       "75%     110.320000   132.350000    31.731000  22485.002700   146.980000   \n",
       "max     111.950000   153.093000    84.856000  45139.001500   171.340000   \n",
       "\n",
       "          ...                77           78           79           80  \\\n",
       "count     ...       4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean      ...          4.514619     4.538804    52.535717    48.223883   \n",
       "std       ...          1.388181     1.372625    30.698940    34.171762   \n",
       "min       ...          1.887000     1.928000   -13.840000   -26.250000   \n",
       "25%       ...          3.274000     3.312750    28.690000    18.985000   \n",
       "50%       ...          4.805000     4.822000    53.615000    54.730000   \n",
       "75%       ...          5.445000     5.450000    72.630000    71.000000   \n",
       "max       ...          7.875000     7.855000   146.010000   151.500000   \n",
       "\n",
       "                81           82           83           84           85  \\\n",
       "count  4280.000000  4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean     33.826551     4.348641     4.476098     4.485189     4.547887   \n",
       "std      34.130836     1.431227     1.400364     1.305526     1.362411   \n",
       "min     -37.500000     1.737800     1.863300     1.924300     1.960500   \n",
       "25%       0.310000     3.074000     3.236875     3.303000     3.337750   \n",
       "50%      49.500000     4.633750     4.770500     4.815500     4.832500   \n",
       "75%      60.212500     5.309250     5.415125     5.448500     5.451125   \n",
       "max     108.500000     7.886000     7.863000     6.636000     7.800000   \n",
       "\n",
       "                86  \n",
       "count  4280.000000  \n",
       "mean    110.571528  \n",
       "std       7.591973  \n",
       "min      96.480000  \n",
       "25%     106.400000  \n",
       "50%     106.400000  \n",
       "75%     117.092500  \n",
       "max     135.840000  \n",
       "\n",
       "[8 rows x 86 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the various indices operate on scales differing by orders of magnitude. It's best to scale the data so that, for example, operations involving multiple indices aren't unduly influenced by a single, massive index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAUlCAYAAAAnU75jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97e80f3b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# N.B. A super-useful trick-ette is to assign the return value of plot to _ \n",
    "# so that you don't get text printed before the plot itself.\n",
    "\n",
    "# _ = pd.concat([data_values_indexed[1],\n",
    "#   data_values_indexed[1070],\n",
    "#   data_values_indexed[788],\n",
    "#   data_values_indexed[926]], axis=1).plot(figsize=(20, 15))\n",
    "\n",
    "_ = data_values_indexed.plot(figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the structure isn't uniformly visible for the indices. Divide each value in an individual index by the maximum value for that index., and then replot. The maximum value of all indices will be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Calculate the max value for each column, prepare to scale data for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      19.1476\n",
       "2     290.2600\n",
       "3      57.0200\n",
       "4     146.1300\n",
       "5    6937.6750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed_max = data_values_indexed.max(axis=0) # max across axis 0 = rows\n",
    "data_values_indexed_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-27</th>\n",
       "      <td>0.964878</td>\n",
       "      <td>0.998932</td>\n",
       "      <td>0.971589</td>\n",
       "      <td>0.966810</td>\n",
       "      <td>0.061136</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.776084</td>\n",
       "      <td>0.778191</td>\n",
       "      <td>0.789677</td>\n",
       "      <td>0.944847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266921</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>-0.072803</td>\n",
       "      <td>-0.118812</td>\n",
       "      <td>-0.291521</td>\n",
       "      <td>0.246386</td>\n",
       "      <td>0.263767</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.278692</td>\n",
       "      <td>0.913796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-26</th>\n",
       "      <td>0.963797</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.969660</td>\n",
       "      <td>0.970574</td>\n",
       "      <td>0.061692</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.775672</td>\n",
       "      <td>0.769327</td>\n",
       "      <td>0.782403</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>-0.071639</td>\n",
       "      <td>-0.116502</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>0.244484</td>\n",
       "      <td>0.261669</td>\n",
       "      <td>0.320223</td>\n",
       "      <td>0.276897</td>\n",
       "      <td>0.915047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-25</th>\n",
       "      <td>0.965406</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.987899</td>\n",
       "      <td>0.964757</td>\n",
       "      <td>0.777330</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.773634</td>\n",
       "      <td>0.776895</td>\n",
       "      <td>0.790452</td>\n",
       "      <td>0.943212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267556</td>\n",
       "      <td>0.272438</td>\n",
       "      <td>-0.076091</td>\n",
       "      <td>-0.121452</td>\n",
       "      <td>-0.295207</td>\n",
       "      <td>0.247908</td>\n",
       "      <td>0.264848</td>\n",
       "      <td>0.323282</td>\n",
       "      <td>0.279295</td>\n",
       "      <td>0.913648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-24</th>\n",
       "      <td>0.965500</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.965989</td>\n",
       "      <td>0.777330</td>\n",
       "      <td>0.998794</td>\n",
       "      <td>0.774039</td>\n",
       "      <td>0.787991</td>\n",
       "      <td>0.800951</td>\n",
       "      <td>0.943037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269968</td>\n",
       "      <td>0.274729</td>\n",
       "      <td>-0.076570</td>\n",
       "      <td>-0.121650</td>\n",
       "      <td>-0.294378</td>\n",
       "      <td>0.246881</td>\n",
       "      <td>0.263296</td>\n",
       "      <td>0.321052</td>\n",
       "      <td>0.277115</td>\n",
       "      <td>0.914605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-23</th>\n",
       "      <td>0.967019</td>\n",
       "      <td>0.971612</td>\n",
       "      <td>0.969309</td>\n",
       "      <td>0.967016</td>\n",
       "      <td>0.777330</td>\n",
       "      <td>0.998794</td>\n",
       "      <td>0.785065</td>\n",
       "      <td>0.789695</td>\n",
       "      <td>0.812696</td>\n",
       "      <td>0.942862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265651</td>\n",
       "      <td>0.270528</td>\n",
       "      <td>-0.074036</td>\n",
       "      <td>-0.119736</td>\n",
       "      <td>-0.290783</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.260753</td>\n",
       "      <td>0.318264</td>\n",
       "      <td>0.274808</td>\n",
       "      <td>0.914826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6   \\\n",
       "0                                                                        \n",
       "2016-05-27  0.964878  0.998932  0.971589  0.966810  0.061136  0.999107   \n",
       "2016-05-26  0.963797  0.980776  0.969660  0.970574  0.061692  0.999062   \n",
       "2016-05-25  0.965406  0.969476  0.987899  0.964757  0.777330  0.998883   \n",
       "2016-05-24  0.965500  0.974333  0.983164  0.965989  0.777330  0.998794   \n",
       "2016-05-23  0.967019  0.971612  0.969309  0.967016  0.777330  0.998794   \n",
       "\n",
       "                  7         8         9         10    ...           77  \\\n",
       "0                                                     ...                \n",
       "2016-05-27  0.776084  0.778191  0.789677  0.944847    ...     0.266921   \n",
       "2016-05-26  0.775672  0.769327  0.782403  0.944321    ...     0.267175   \n",
       "2016-05-25  0.773634  0.776895  0.790452  0.943212    ...     0.267556   \n",
       "2016-05-24  0.774039  0.787991  0.800951  0.943037    ...     0.269968   \n",
       "2016-05-23  0.785065  0.789695  0.812696  0.942862    ...     0.265651   \n",
       "\n",
       "                  78        79        80        81        82        83  \\\n",
       "0                                                                        \n",
       "2016-05-27  0.272183 -0.072803 -0.118812 -0.291521  0.246386  0.263767   \n",
       "2016-05-26  0.272311 -0.071639 -0.116502 -0.289677  0.244484  0.261669   \n",
       "2016-05-25  0.272438 -0.076091 -0.121452 -0.295207  0.247908  0.264848   \n",
       "2016-05-24  0.274729 -0.076570 -0.121650 -0.294378  0.246881  0.263296   \n",
       "2016-05-23  0.270528 -0.074036 -0.119736 -0.290783  0.244040  0.260753   \n",
       "\n",
       "                  84        85        86  \n",
       "0                                         \n",
       "2016-05-27  0.321429  0.278692  0.913796  \n",
       "2016-05-26  0.320223  0.276897  0.915047  \n",
       "2016-05-25  0.323282  0.279295  0.913648  \n",
       "2016-05-24  0.321052  0.277115  0.914605  \n",
       "2016-05-23  0.318264  0.274808  0.914826  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed_scaled = data_values_indexed / data_values_indexed_max\n",
    "data_values_indexed_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Plot the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = data_values_indexed_scaled.plot(figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Auto-correlations\n",
    "\n",
    "Next, plot autocorrelations for each of the indices. The autocorrelations determine correlations between current values of the index and lagged values of the same index. The goal is to determine whether the lagged values are reliable indicators of the current values. If they are, then we've identified a correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "_ = autocorrelation_plot(data_values_indexed_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2300 lagged days, we observe positive auto-correlations.\n",
    "This suggests that as the variables increase, they tend to keep on increasing. Momentum.\n",
    "\n",
    "After 2300 lagged days, we observe negative auto-correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Skip: Just a reminder of the PCA columns we selected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_cols_pca = [ 0,1,\n",
    "#                   1070,788,926,112,69,574,654,1160,527,323,\n",
    "#                   397,118,774,1028,1034,655,907,736,251,388,\n",
    "#                   327,243,705,303,1146,467,136,1006,600,15,\n",
    "#                   231,290,131,782,20,1048,630,1173,431,856,\n",
    "#                   67,299,838,639,53,932,870,938,1061\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17) Scatter plots of the first 20 of our 86 variables vs USDMXN(varid=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _ = scatter_matrix(data_values_indexed_scaled)\n",
    "dvis = data_values_indexed_scaled\n",
    "\n",
    "_ = scatter_matrix(\n",
    "      pd.concat(\n",
    "      [ \n",
    "        dvis[ 1],dvis[ 2],dvis[ 3],dvis[ 4],dvis[ 5],dvis[ 6],dvis[ 7],dvis[ 8],dvis[ 9],dvis[10],\n",
    "        dvis[11],dvis[12],dvis[13],dvis[14],dvis[15],dvis[16],dvis[17],dvis[18],dvis[19],dvis[20],\n",
    "      ], axis=1), figsize=(15, 15), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18) Remind ourselves what our scaled data (of price or index LEVELS) looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19) Calculate Log Returns on our scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret = pd.DataFrame()\n",
    "data_values_indexed_scaled_logret = np.log(data_values_indexed_scaled/data_values_indexed_scaled.shift(-1)) # note dates are reverse-chrono\n",
    "\n",
    "data_values_indexed_scaled_logret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2000/01/07 to 2016/05/27 = 1 header row + 4279 data rows\n",
    "# print data_values_indexed_scaled_logret.head()\n",
    "# print data_values_indexed_scaled_logret.tail()\n",
    "print 'NumRowsIncludeHeader = len(data_values_indexed_scaled_logret) = ' + str(len(data_values_indexed_scaled_logret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20) Replace inf, NaN in data with Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret = data_values_indexed_scaled_logret.replace([np.inf, -np.inf, np.nan], 0)\n",
    "data_values_indexed_scaled_logret.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21) Skip: Fill the Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas includes a very convenient function for filling gaps in the data.\n",
    "# data_values_indexed_scaled_logret = data_values_indexed_scaled_logret.fillna(method='ffill')\n",
    "data_values_indexed_scaled_logret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22) Plot log returns of scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = data_values_indexed_scaled_logret.plot(figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23) Auto-Correlations of log returns of scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "_ = autocorrelation_plot(data_values_indexed_scaled_logret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no auto-correlations, so we are good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24) Skip: Just a reminder of the PCA50 Columns we selected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_cols_pca = [ 0,1,\n",
    "#                   1070,788,926,112,69,574,654,1160,527,323,\n",
    "#                   397,118,774,1028,1034,655,907,736,251,388,\n",
    "#                   327,243,705,303,1146,467,136,1006,600,15,\n",
    "#                   231,290,131,782,20,1048,630,1173,431,856,\n",
    "#                   67,299,838,639,53,932,870,938,1061\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25) Scatter plots of log returns of first 20 of the 86 variables where log-returns of USDMXN(varid=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _ = scatter_matrix(data_values_indexed_scaled_logret)   # takes long time, becareful, save work first\n",
    "dvislr = data_values_indexed_scaled_logret\n",
    "\n",
    "_ = scatter_matrix(\n",
    "      pd.concat(\n",
    "      [ \n",
    "        dvislr[ 1],dvislr[ 2],dvislr[ 3],dvislr[ 4],dvislr[ 5],dvislr[ 6],dvislr[ 7],dvislr[ 8],dvislr[ 9],dvislr[10],\n",
    "        dvislr[11],dvislr[12],dvislr[13],dvislr[14],dvislr[15],dvislr[16],dvislr[17],dvislr[18],dvislr[19],dvislr[20],\n",
    "      ], axis=1), figsize=(15, 15), diagonal='kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing up the EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you've done a good enough job of exploratory data analysis. You've visualized our data and come to know it better. \n",
    "You've transformed it into a form that is useful for modelling, log returns, and looked at how indices relate to each other. \n",
    "\n",
    "What should we think so far?\n",
    "\n",
    "Cloud Datalab is working great. With just a few lines of code, you were able to munge the data, visualize the changes, and make decisions. You could easily analyze and iterate. This is a common feature of iPython, but the advantage here is that Cloud Datalab is a managed service that you can simply click and use, so you can focus on your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can see a model:\n",
    "\n",
    "* We'll predict whether the USDMXN close today will be higher or lower than yesterday.\n",
    "\n",
    "Predicting whether the log return of the USDMXN is positive or negative is a classification problem. \n",
    "That is, we want to choose one option from a finite set of options, in this case positive or negative. \n",
    "This is the base case of classification where we have only two values to choose from, known as binary classification, or logistic regression.\n",
    "\n",
    "Machine learning models are very good at finding weak signals from data.\n",
    "In machine learning, as in most things, there are subtle tradeoffs happening, but in general good data is better than good algorithms, which are better than good frameworks. \n",
    "You need all three pillars but in that order of importance: data, algorithms, frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow](https://tensorflow.org) is an open source software library, initiated by Google, for numerical computation using data flow graphs. TensorFlow is based on Google's machine learning expertise and is the next generation framework used internally at Google for tasks such as translation and image recognition. It's a wonderful framework for machine learning because it's expressive, efficient, and easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering for TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a training and testing perspective, time series data is easy. Training data should come from events that happened before test data events, and be contiguous in time.  Otherwise,  your model would be trained on events from \"the future\", at least as compared to the test data. It would then likely perform badly in practice, because you can’t really have access to data from the future. That means random sampling or cross validation don't apply to time series data. Decide on a training-versus-testing split, and divide your data into training and test datasets.\n",
    "\n",
    "In this case, you'll create the features together with two additional columns:\n",
    "\n",
    "* usdmxn_logret_positive, which is 1 if the log return of the USDMXN close is positive, and 0 otherwise. \n",
    "* usdmxn_logret_negative, which is 1 if the log return of the USDMXN close is negative, and 1 otherwise. \n",
    "\n",
    "We'll use 80% of our data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Binary Classification (BC) = Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Step 01: Indicator Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 00: Original: Initialize indicator columns to 0\n",
    "data_values_indexed_scaled_logret['usdmxn_logret_positive'] = 0\n",
    "data_values_indexed_scaled_logret['usdmxn_logret_negative'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 00: Populate results columns according to actual usdmxn returns (positive or negative)\n",
    "data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] >= 0, 'usdmxn_logret_positive'] = 1\n",
    "data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] <  0, 'usdmxn_logret_negative'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 01: Noise Cancellation\n",
    "data_values_indexed_scaled_logret['usdmxn_logret_positive_0050bp'] = 0\n",
    "data_values_indexed_scaled_logret['usdmxn_logret_negative_0050bp'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 01: Populate results columns according to actual usdmxn returns (outside noise zone above or below)\n",
    "data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] >= 0.0050, 'usdmxn_logret_positive_0050bp'] = 1\n",
    "data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] <  -0.0050, 'usdmxn_logret_negative_0050bp'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 02: Stratification\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0150bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0150bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0140bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0140bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0130bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0130bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0120bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0120bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0110bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0110bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0100bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0100bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0090bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0090bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0080bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0080bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0070bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0070bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0060bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0060bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0050bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0050bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0040bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0040bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0030bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0030bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0020bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0020bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0010bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0010bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_+0000bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_+0000bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0010bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0010bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0020bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0020bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0030bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0030bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0040bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0040bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0050bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0050bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0060bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0060bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0070bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0070bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0080bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0080bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0090bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0090bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0100bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0100bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0110bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0110bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0120bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0120bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0130bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0130bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0140bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0140bp_and_below'] = 0;\n",
    "# data_values_indexed_scaled_logret['usdmxn_logret_-0150bp_and_above'] = 0; data_values_indexed_scaled_logret['usdmxn_logret_-0150bp_and_below'] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 02: Stratification: Initialize\n",
    "for d_bp in xrange(-150,160,10): # -150:10:+150\n",
    "  d = d_bp / 10000.00\n",
    "  s_above = 'usdmxn_logret_' + '{0:+05d}'.format(d_bp) + 'bp_and_above'\n",
    "  s_below = 'usdmxn_logret_' + '{0:+05d}'.format(d_bp) + 'bp_and_below'\n",
    "  # print d\n",
    "  # print s_above\n",
    "  # print s_below\n",
    "  data_values_indexed_scaled_logret[s_above] = 0;\n",
    "  data_values_indexed_scaled_logret[s_below] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 02: Stratification: Populate results columns according to actual usdmxn returns (above or below each level)\n",
    "for d_bp in xrange(-150,160,10): # -150:10:+150\n",
    "  d = d_bp / 10000.00\n",
    "  s_above = 'usdmxn_logret_' + '{0:+05d}'.format(d_bp) + 'bp_and_above'\n",
    "  s_below = 'usdmxn_logret_' + '{0:+05d}'.format(d_bp) + 'bp_and_below'\n",
    "  # print d\n",
    "  # print s_above\n",
    "  # print s_below\n",
    "  data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] >= d, s_above] = 1\n",
    "  data_values_indexed_scaled_logret.ix[data_values_indexed_scaled_logret[1] <  d, s_below] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_values_indexed_scaled_logret.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Step 01.01: Remove data noise [-0.5%, 0.5%], 4280 left with 1437 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dvislrnr = data_values_indexed_scaled_logret (noise removed)\n",
    "dvislrnr =  data_values_indexed_scaled_logret\n",
    "\n",
    "# df[(df.A == 1) & (df.D == 6)]\n",
    "dvislrnr = dvislrnr[ \n",
    "    (dvislrnr['usdmxn_logret_+0050bp_and_above'] == 1) |\n",
    "    (dvislrnr['usdmxn_logret_-0050bp_and_below'] == 1)\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>usdmxn_logret_+0110bp_and_above</th>\n",
       "      <th>usdmxn_logret_+0110bp_and_below</th>\n",
       "      <th>usdmxn_logret_+0120bp_and_above</th>\n",
       "      <th>usdmxn_logret_+0120bp_and_below</th>\n",
       "      <th>usdmxn_logret_+0130bp_and_above</th>\n",
       "      <th>usdmxn_logret_+0130bp_and_below</th>\n",
       "      <th>usdmxn_logret_+0140bp_and_above</th>\n",
       "      <th>usdmxn_logret_+0140bp_and_below</th>\n",
       "      <th>usdmxn_logret_+0150bp_and_above</th>\n",
       "      <th>usdmxn_logret_+0150bp_and_below</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "      <td>4280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.951636</td>\n",
       "      <td>0.037850</td>\n",
       "      <td>0.962150</td>\n",
       "      <td>0.027336</td>\n",
       "      <td>0.972664</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.978271</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.982009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>0.018346</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.026630</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214560</td>\n",
       "      <td>0.214560</td>\n",
       "      <td>0.190857</td>\n",
       "      <td>0.190857</td>\n",
       "      <td>0.163081</td>\n",
       "      <td>0.163081</td>\n",
       "      <td>0.145814</td>\n",
       "      <td>0.145814</td>\n",
       "      <td>0.132933</td>\n",
       "      <td>0.132933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.066527</td>\n",
       "      <td>-0.614143</td>\n",
       "      <td>-0.101624</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-2.533711</td>\n",
       "      <td>-0.007372</td>\n",
       "      <td>-0.166175</td>\n",
       "      <td>-0.123921</td>\n",
       "      <td>-0.385704</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.005990</td>\n",
       "      <td>-0.008798</td>\n",
       "      <td>-0.001978</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.009255</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.070259</td>\n",
       "      <td>0.137621</td>\n",
       "      <td>0.133531</td>\n",
       "      <td>0.020071</td>\n",
       "      <td>0.700986</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.229973</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.697777</td>\n",
       "      <td>0.083623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1            2            3            4            5  \\\n",
       "count  4280.000000  4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean      0.000155     0.000704     0.000561     0.000041     0.000024   \n",
       "std       0.006766     0.020756     0.018346     0.004670     0.056946   \n",
       "min      -0.066527    -0.614143    -0.101624    -0.190591    -2.533711   \n",
       "25%      -0.003348    -0.005990    -0.008798    -0.001978    -0.003060   \n",
       "50%      -0.000076     0.000000     0.000000     0.000085     0.000000   \n",
       "75%       0.003311     0.008082     0.009255     0.002250     0.002376   \n",
       "max       0.070259     0.137621     0.133531     0.020071     0.700986   \n",
       "\n",
       "                 6            7            8            9           10  \\\n",
       "count  4280.000000  4280.000000  4280.000000  4280.000000  4280.000000   \n",
       "mean      0.000020    -0.000025     0.000204     0.000108     0.000070   \n",
       "std       0.000857     0.010163     0.007857     0.026630     0.003441   \n",
       "min      -0.007372    -0.166175    -0.123921    -0.385704    -0.024960   \n",
       "25%      -0.000318     0.000000    -0.001618    -0.002285    -0.001332   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000073   \n",
       "75%       0.000407     0.000000     0.001508     0.002399     0.001593   \n",
       "max       0.005774     0.229973     0.108471     0.697777     0.083623   \n",
       "\n",
       "                    ...                 usdmxn_logret_+0110bp_and_above  \\\n",
       "count               ...                                     4280.000000   \n",
       "mean                ...                                        0.048364   \n",
       "std                 ...                                        0.214560   \n",
       "min                 ...                                        0.000000   \n",
       "25%                 ...                                        0.000000   \n",
       "50%                 ...                                        0.000000   \n",
       "75%                 ...                                        0.000000   \n",
       "max                 ...                                        1.000000   \n",
       "\n",
       "       usdmxn_logret_+0110bp_and_below  usdmxn_logret_+0120bp_and_above  \\\n",
       "count                      4280.000000                      4280.000000   \n",
       "mean                          0.951636                         0.037850   \n",
       "std                           0.214560                         0.190857   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           1.000000                         0.000000   \n",
       "50%                           1.000000                         0.000000   \n",
       "75%                           1.000000                         0.000000   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       usdmxn_logret_+0120bp_and_below  usdmxn_logret_+0130bp_and_above  \\\n",
       "count                      4280.000000                      4280.000000   \n",
       "mean                          0.962150                         0.027336   \n",
       "std                           0.190857                         0.163081   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           1.000000                         0.000000   \n",
       "50%                           1.000000                         0.000000   \n",
       "75%                           1.000000                         0.000000   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       usdmxn_logret_+0130bp_and_below  usdmxn_logret_+0140bp_and_above  \\\n",
       "count                      4280.000000                      4280.000000   \n",
       "mean                          0.972664                         0.021729   \n",
       "std                           0.163081                         0.145814   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           1.000000                         0.000000   \n",
       "50%                           1.000000                         0.000000   \n",
       "75%                           1.000000                         0.000000   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       usdmxn_logret_+0140bp_and_below  usdmxn_logret_+0150bp_and_above  \\\n",
       "count                      4280.000000                      4280.000000   \n",
       "mean                          0.978271                         0.017991   \n",
       "std                           0.145814                         0.132933   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           1.000000                         0.000000   \n",
       "50%                           1.000000                         0.000000   \n",
       "75%                           1.000000                         0.000000   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       usdmxn_logret_+0150bp_and_below  \n",
       "count                      4280.000000  \n",
       "mean                          0.982009  \n",
       "std                           0.132933  \n",
       "min                           0.000000  \n",
       "25%                           1.000000  \n",
       "50%                           1.000000  \n",
       "75%                           1.000000  \n",
       "max                           1.000000  \n",
       "\n",
       "[8 rows x 152 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_values_indexed_scaled_logret.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Step 02: Split data into training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training test data empty shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usdmxn_logret_positive</th>\n",
       "      <th>usdmxn_logret_negative</th>\n",
       "      <th>usdmxn_logret_-0150bp_and_above</th>\n",
       "      <th>usdmxn_logret_-0150bp_and_below</th>\n",
       "      <th>usdmxn_logret_-0140bp_and_above</th>\n",
       "      <th>usdmxn_logret_-0140bp_and_below</th>\n",
       "      <th>usdmxn_logret_-0130bp_and_above</th>\n",
       "      <th>usdmxn_logret_-0130bp_and_below</th>\n",
       "      <th>usdmxn_logret_-0120bp_and_above</th>\n",
       "      <th>usdmxn_logret_-0120bp_and_below</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [usdmxn_logret_positive, usdmxn_logret_negative, usdmxn_logret_-0150bp_and_above, usdmxn_logret_-0150bp_and_below, usdmxn_logret_-0140bp_and_above, usdmxn_logret_-0140bp_and_below, usdmxn_logret_-0130bp_and_above, usdmxn_logret_-0130bp_and_below, usdmxn_logret_-0120bp_and_above, usdmxn_logret_-0120bp_and_below, usdmxn_logret_-0110bp_and_above, usdmxn_logret_-0110bp_and_below, usdmxn_logret_-0100bp_and_above, usdmxn_logret_-0100bp_and_below, usdmxn_logret_-0090bp_and_above, usdmxn_logret_-0090bp_and_below, usdmxn_logret_-0080bp_and_above, usdmxn_logret_-0080bp_and_below, usdmxn_logret_-0070bp_and_above, usdmxn_logret_-0070bp_and_below, usdmxn_logret_-0060bp_and_above, usdmxn_logret_-0060bp_and_below, usdmxn_logret_-0050bp_and_above, usdmxn_logret_-0050bp_and_below, usdmxn_logret_-0040bp_and_above, usdmxn_logret_-0040bp_and_below, usdmxn_logret_-0030bp_and_above, usdmxn_logret_-0030bp_and_below, usdmxn_logret_-0020bp_and_above, usdmxn_logret_-0020bp_and_below, usdmxn_logret_-0010bp_and_above, usdmxn_logret_-0010bp_and_below, usdmxn_logret_+0000bp_and_above, usdmxn_logret_+0000bp_and_below, usdmxn_logret_+0010bp_and_above, usdmxn_logret_+0010bp_and_below, usdmxn_logret_+0020bp_and_above, usdmxn_logret_+0020bp_and_below, usdmxn_logret_+0030bp_and_above, usdmxn_logret_+0030bp_and_below, usdmxn_logret_+0040bp_and_above, usdmxn_logret_+0040bp_and_below, usdmxn_logret_+0050bp_and_above, usdmxn_logret_+0050bp_and_below, usdmxn_logret_+0060bp_and_above, usdmxn_logret_+0060bp_and_below, usdmxn_logret_+0070bp_and_above, usdmxn_logret_+0070bp_and_below, usdmxn_logret_+0080bp_and_above, usdmxn_logret_+0080bp_and_below, usdmxn_logret_+0090bp_and_above, usdmxn_logret_+0090bp_and_below, usdmxn_logret_+0100bp_and_above, usdmxn_logret_+0100bp_and_below, usdmxn_logret_+0110bp_and_above, usdmxn_logret_+0110bp_and_below, usdmxn_logret_+0120bp_and_above, usdmxn_logret_+0120bp_and_below, usdmxn_logret_+0130bp_and_above, usdmxn_logret_+0130bp_and_below, usdmxn_logret_+0140bp_and_above, usdmxn_logret_+0140bp_and_below, usdmxn_logret_+0150bp_and_above, usdmxn_logret_+0150bp_and_below, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 150 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_test_data\n",
    "# col 01-02 = 02 cols = indicators of results\n",
    "# col 03-88 = 86 cols = inputs\n",
    "training_test_data = pd.DataFrame(\n",
    "  columns=[\n",
    "    'usdmxn_logret_positive', 'usdmxn_logret_negative',\n",
    "\n",
    "    # 'usdmxn_logret_positive_0050bp', 'usdmxn_logret_negative_0050bp',\n",
    "\n",
    "    'usdmxn_logret_-0150bp_and_above', 'usdmxn_logret_-0150bp_and_below',\n",
    "    'usdmxn_logret_-0140bp_and_above', 'usdmxn_logret_-0140bp_and_below',\n",
    "    'usdmxn_logret_-0130bp_and_above', 'usdmxn_logret_-0130bp_and_below',\n",
    "    'usdmxn_logret_-0120bp_and_above', 'usdmxn_logret_-0120bp_and_below',\n",
    "    'usdmxn_logret_-0110bp_and_above', 'usdmxn_logret_-0110bp_and_below',\n",
    "    'usdmxn_logret_-0100bp_and_above', 'usdmxn_logret_-0100bp_and_below',\n",
    "    'usdmxn_logret_-0090bp_and_above', 'usdmxn_logret_-0090bp_and_below',\n",
    "    'usdmxn_logret_-0080bp_and_above', 'usdmxn_logret_-0080bp_and_below',\n",
    "    'usdmxn_logret_-0070bp_and_above', 'usdmxn_logret_-0070bp_and_below',\n",
    "    'usdmxn_logret_-0060bp_and_above', 'usdmxn_logret_-0060bp_and_below',\n",
    "    'usdmxn_logret_-0050bp_and_above', 'usdmxn_logret_-0050bp_and_below',\n",
    "    'usdmxn_logret_-0040bp_and_above', 'usdmxn_logret_-0040bp_and_below',\n",
    "    'usdmxn_logret_-0030bp_and_above', 'usdmxn_logret_-0030bp_and_below',\n",
    "    'usdmxn_logret_-0020bp_and_above', 'usdmxn_logret_-0020bp_and_below',\n",
    "    'usdmxn_logret_-0010bp_and_above', 'usdmxn_logret_-0010bp_and_below',\n",
    "    'usdmxn_logret_+0000bp_and_above', 'usdmxn_logret_+0000bp_and_below',\n",
    "    'usdmxn_logret_+0010bp_and_above', 'usdmxn_logret_+0010bp_and_below',\n",
    "    'usdmxn_logret_+0020bp_and_above', 'usdmxn_logret_+0020bp_and_below',\n",
    "    'usdmxn_logret_+0030bp_and_above', 'usdmxn_logret_+0030bp_and_below',\n",
    "    'usdmxn_logret_+0040bp_and_above', 'usdmxn_logret_+0040bp_and_below',\n",
    "    'usdmxn_logret_+0050bp_and_above', 'usdmxn_logret_+0050bp_and_below',\n",
    "    'usdmxn_logret_+0060bp_and_above', 'usdmxn_logret_+0060bp_and_below',\n",
    "    'usdmxn_logret_+0070bp_and_above', 'usdmxn_logret_+0070bp_and_below',\n",
    "    'usdmxn_logret_+0080bp_and_above', 'usdmxn_logret_+0080bp_and_below',\n",
    "    'usdmxn_logret_+0090bp_and_above', 'usdmxn_logret_+0090bp_and_below',\n",
    "    'usdmxn_logret_+0100bp_and_above', 'usdmxn_logret_+0100bp_and_below',\n",
    "    'usdmxn_logret_+0110bp_and_above', 'usdmxn_logret_+0110bp_and_below',\n",
    "    'usdmxn_logret_+0120bp_and_above', 'usdmxn_logret_+0120bp_and_below',\n",
    "    'usdmxn_logret_+0130bp_and_above', 'usdmxn_logret_+0130bp_and_below',\n",
    "    'usdmxn_logret_+0140bp_and_above', 'usdmxn_logret_+0140bp_and_below',\n",
    "    'usdmxn_logret_+0150bp_and_above', 'usdmxn_logret_+0150bp_and_below',\n",
    "\n",
    "    '1','2','3','4','5','6','7','8','9','10',\n",
    "    '11','12','13','14','15','16','17','18','19','20',\n",
    "    '21','22','23','24','25','26','27','28','29','30',\n",
    "    '31','32','33','34','35','36','37','38','39','40',\n",
    "    '41','42','43','44','45','46','47','48','49','50',\n",
    "    '51','52','53','54','55','56','57','58','59','60',\n",
    "    '61','62','63','64','65','66','67','68','69','70',\n",
    "    '71','72','73','74','75','76','77','78','79','80',\n",
    "    '81','82','83','84','85','86',\n",
    "  ])\n",
    "\n",
    "training_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumRowsIncludeHeader = len(data_values_indexed_scaled_logret) = 4280\n"
     ]
    }
   ],
   "source": [
    "# 2000/01/07 to 2016/05/27 = 1 header row + 4279 data rows\n",
    "# after noise reduction, left with 1437 rows\n",
    "\n",
    "# print data_values_indexed_scaled_logret.head()\n",
    "# print data_values_indexed_scaled_logret.tail()\n",
    "print 'NumRowsIncludeHeader = len(data_values_indexed_scaled_logret) = ' + str(len(data_values_indexed_scaled_logret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# row 0      = header\n",
    "# row 1-4279 = data\n",
    "# NumRowsIncludeHeader = len(data_values_indexed_scaled_logret) = 4280 = 0-4279\n",
    "# Start from row 7, so we can have up to (7-1) lookback days\n",
    "\n",
    "dvislr =  data_values_indexed_scaled_logret\n",
    "\n",
    "for i in range(7, len(data_values_indexed_scaled_logret)): # [7, 4280) = [7,4279] \n",
    "\n",
    "  # 00: original\n",
    "  #   usdmxn_logret_positive = data_values_indexed_scaled_logret['usdmxn_logret_positive'].ix[i]\n",
    "  #   usdmxn_logret_negative = data_values_indexed_scaled_logret['usdmxn_logret_negative'].ix[i]\n",
    "\n",
    "  # 01: noise cancellation\n",
    "  #   usdmxn_logret_positive_0050bp = data_values_indexed_scaled_logret['usdmxn_logret_positive_0050bp'].ix[i]\n",
    "  #   usdmxn_logret_negative_0050bp = data_values_indexed_scaled_logret['usdmxn_logret_negative_0050bp'].ix[i]\n",
    "\n",
    "  # 02: stratification\n",
    "  \n",
    "  # +50\n",
    "  usdmxn_logret_p0050bp_and_above = dvislr['usdmxn_logret_+0050bp_and_above'].ix[i]\n",
    "  usdmxn_logret_p0050bp_and_below = dvislr['usdmxn_logret_+0050bp_and_below'].ix[i]\n",
    "  # +00\n",
    "  usdmxn_logret_p0000bp_and_above = dvislr['usdmxn_logret_+0000bp_and_above'].ix[i]\n",
    "  usdmxn_logret_p0000bp_and_below = dvislr['usdmxn_logret_+0000bp_and_below'].ix[i]  \n",
    "  # -50 \n",
    "  usdmxn_logret_m0050bp_and_above = dvislr['usdmxn_logret_-0050bp_and_above'].ix[i]\n",
    "  usdmxn_logret_m0050bp_and_below = dvislr['usdmxn_logret_-0050bp_and_below'].ix[i]\n",
    "\n",
    "  # Select 2 levels: up and dn\n",
    "  bc_up = usdmxn_logret_p0050bp_and_above\n",
    "  bc_dn = usdmxn_logret_p0050bp_and_below\n",
    "  \n",
    "  #   v_001_Tm005 = data_values_indexed_scaled_logret['1'].ix[i-5]  # lookback 1d\n",
    "\n",
    "  v_001_Tm000 = dvislr[1].ix[i];  v_002_Tm000 = dvislr[2].ix[i];  v_003_Tm000 = dvislr[3].ix[i];  v_004_Tm000 = dvislr[4].ix[i];  v_005_Tm000 = dvislr[5].ix[i];\n",
    "  v_006_Tm000 = dvislr[6].ix[i];  v_007_Tm000 = dvislr[7].ix[i];  v_008_Tm000 = dvislr[8].ix[i];  v_009_Tm000 = dvislr[9].ix[i];  v_010_Tm000 = dvislr[10].ix[i]\n",
    "\n",
    "  v_011_Tm000 = dvislr[11].ix[i]; v_012_Tm000 = dvislr[12].ix[i]; v_013_Tm000 = dvislr[13].ix[i]; v_014_Tm000 = dvislr[14].ix[i]; v_015_Tm000 = dvislr[15].ix[i];\n",
    "  v_016_Tm000 = dvislr[16].ix[i]; v_017_Tm000 = dvislr[17].ix[i]; v_018_Tm000 = dvislr[18].ix[i]; v_019_Tm000 = dvislr[19].ix[i]; v_020_Tm000 = dvislr[20].ix[i];\n",
    "  \n",
    "  v_021_Tm000 = dvislr[21].ix[i]; v_022_Tm000 = dvislr[22].ix[i]; v_023_Tm000 = dvislr[23].ix[i]; v_024_Tm000 = dvislr[24].ix[i]; v_025_Tm000 = dvislr[25].ix[i];\n",
    "  v_026_Tm000 = dvislr[26].ix[i]; v_027_Tm000 = dvislr[27].ix[i]; v_028_Tm000 = dvislr[28].ix[i]; v_029_Tm000 = dvislr[29].ix[i]; v_030_Tm000 = dvislr[30].ix[i];\n",
    "\n",
    "  v_031_Tm000 = dvislr[31].ix[i]; v_032_Tm000 = dvislr[32].ix[i]; v_033_Tm000 = dvislr[33].ix[i]; v_034_Tm000 = dvislr[34].ix[i]; v_035_Tm000 = dvislr[35].ix[i];\n",
    "  v_036_Tm000 = dvislr[36].ix[i]; v_037_Tm000 = dvislr[37].ix[i]; v_038_Tm000 = dvislr[38].ix[i]; v_039_Tm000 = dvislr[39].ix[i]; v_040_Tm000 = dvislr[40].ix[i];\n",
    "\n",
    "  v_041_Tm000 = dvislr[41].ix[i]; v_042_Tm000 = dvislr[42].ix[i]; v_043_Tm000 = dvislr[43].ix[i]; v_044_Tm000 = dvislr[44].ix[i]; v_045_Tm000 = dvislr[45].ix[i];\n",
    "  v_046_Tm000 = dvislr[46].ix[i]; v_047_Tm000 = dvislr[47].ix[i]; v_048_Tm000 = dvislr[48].ix[i]; v_049_Tm000 = dvislr[49].ix[i]; v_050_Tm000 = dvislr[50].ix[i];\n",
    "\n",
    "  v_051_Tm000 = dvislr[51].ix[i]; v_052_Tm000 = dvislr[52].ix[i]; v_053_Tm000 = dvislr[53].ix[i]; v_054_Tm000 = dvislr[54].ix[i]; v_055_Tm000 = dvislr[55].ix[i];\n",
    "  v_056_Tm000 = dvislr[56].ix[i]; v_057_Tm000 = dvislr[57].ix[i]; v_058_Tm000 = dvislr[58].ix[i]; v_059_Tm000 = dvislr[59].ix[i]; v_060_Tm000 = dvislr[60].ix[i];\n",
    "\n",
    "  v_061_Tm000 = dvislr[61].ix[i]; v_062_Tm000 = dvislr[62].ix[i]; v_063_Tm000 = dvislr[63].ix[i]; v_064_Tm000 = dvislr[64].ix[i]; v_065_Tm000 = dvislr[65].ix[i];\n",
    "  v_066_Tm000 = dvislr[66].ix[i]; v_067_Tm000 = dvislr[67].ix[i]; v_068_Tm000 = dvislr[68].ix[i]; v_069_Tm000 = dvislr[69].ix[i]; v_070_Tm000 = dvislr[70].ix[i];\n",
    "\n",
    "  v_071_Tm000 = dvislr[71].ix[i]; v_072_Tm000 = dvislr[72].ix[i]; v_073_Tm000 = dvislr[73].ix[i]; v_074_Tm000 = dvislr[74].ix[i]; v_075_Tm000 = dvislr[75].ix[i];\n",
    "  v_076_Tm000 = dvislr[76].ix[i]; v_077_Tm000 = dvislr[77].ix[i]; v_078_Tm000 = dvislr[78].ix[i]; v_079_Tm000 = dvislr[79].ix[i]; v_080_Tm000 = dvislr[80].ix[i];\n",
    "\n",
    "  v_081_Tm000 = dvislr[81].ix[i]; v_082_Tm000 = dvislr[82].ix[i]; v_083_Tm000 = dvislr[83].ix[i]; v_084_Tm000 = dvislr[84].ix[i]; v_085_Tm000 = dvislr[85].ix[i];\n",
    "  v_086_Tm000 = dvislr[86].ix[i];\n",
    "\n",
    "  # training_test_data: append data\n",
    "  training_test_data = training_test_data.append(\n",
    "    {\n",
    "#       'usdmxn_logret_positive':usdmxn_logret_positive,\n",
    "#       'usdmxn_logret_negative':usdmxn_logret_negative,\n",
    "#       'usdmxn_logret_positive_0050bp':usdmxn_logret_positive_0050bp,\n",
    "#       'usdmxn_logret_negative_0050bp':usdmxn_logret_negative_0050bp,\n",
    "      \n",
    "      'bc_up':bc_up,\n",
    "      'bc_dn':bc_dn,\n",
    "      \n",
    "      '1':v_001_Tm000,  '2':v_002_Tm000, '3':v_003_Tm000, '4':v_004_Tm000, '5':v_005_Tm000,\n",
    "      '6':v_006_Tm000,  '7':v_007_Tm000, '8':v_008_Tm000, '9':v_009_Tm000, '10':v_010_Tm000,\n",
    "\n",
    "      '11':v_011_Tm000, '12':v_012_Tm000, '13':v_013_Tm000, '14':v_014_Tm000, '15':v_015_Tm000,\n",
    "      '16':v_016_Tm000, '17':v_017_Tm000, '18':v_018_Tm000, '19':v_019_Tm000, '20':v_020_Tm000,\n",
    "\n",
    "      '21':v_021_Tm000, '22':v_022_Tm000, '23':v_023_Tm000, '24':v_024_Tm000, '25':v_025_Tm000,\n",
    "      '26':v_026_Tm000, '27':v_027_Tm000, '28':v_028_Tm000, '29':v_029_Tm000, '30':v_030_Tm000,\n",
    "\n",
    "      '31':v_031_Tm000, '32':v_032_Tm000, '33':v_033_Tm000, '34':v_034_Tm000, '35':v_035_Tm000,\n",
    "      '36':v_036_Tm000, '37':v_037_Tm000, '38':v_038_Tm000, '39':v_039_Tm000, '40':v_040_Tm000,\n",
    "\n",
    "      '41':v_041_Tm000, '42':v_042_Tm000, '43':v_043_Tm000, '44':v_044_Tm000, '45':v_045_Tm000,\n",
    "      '46':v_046_Tm000, '47':v_047_Tm000, '48':v_048_Tm000, '49':v_049_Tm000, '50':v_050_Tm000,\n",
    "\n",
    "      '51':v_051_Tm000, '52':v_052_Tm000, '53':v_053_Tm000, '54':v_054_Tm000, '55':v_055_Tm000,\n",
    "      '56':v_056_Tm000, '57':v_057_Tm000, '58':v_058_Tm000, '59':v_059_Tm000, '60':v_060_Tm000,\n",
    "\n",
    "      '61':v_061_Tm000, '62':v_062_Tm000, '63':v_063_Tm000, '64':v_064_Tm000, '65':v_065_Tm000,\n",
    "      '66':v_066_Tm000, '67':v_067_Tm000, '68':v_068_Tm000, '69':v_069_Tm000, '70':v_070_Tm000,\n",
    "\n",
    "      '71':v_071_Tm000, '72':v_072_Tm000, '73':v_073_Tm000, '74':v_074_Tm000, '75':v_075_Tm000,\n",
    "      '76':v_076_Tm000, '77':v_077_Tm000, '78':v_078_Tm000, '79':v_079_Tm000, '80':v_080_Tm000,\n",
    "      \n",
    "      '81':v_081_Tm000, '82':v_082_Tm000, '83':v_083_Tm000, '84':v_084_Tm000, '85':v_085_Tm000,\n",
    "      '86':v_086_Tm000,\n",
    "      \n",
    "    },\n",
    "    ignore_index=True)\n",
    "  \n",
    "# data_values_indexed_scaled_logret: row [7,4279] \n",
    "# training_test_data               : row [0,4272] = 4273 rows\n",
    "# training_test_data: col 01-02 = 02 cols = binary outputs\n",
    "# training_test_data: col 03-88 = 86 cols = inputs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bc_up</th>\n",
       "      <th>bc_dn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4273.000000</td>\n",
       "      <td>4273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.172244</td>\n",
       "      <td>0.827756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.377637</td>\n",
       "      <td>0.377637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bc_up        bc_dn\n",
       "count  4273.000000  4273.000000\n",
       "mean      0.172244     0.827756\n",
       "std       0.377637     0.377637\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     1.000000\n",
       "50%       0.000000     1.000000\n",
       "75%       0.000000     1.000000\n",
       "max       1.000000     1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_test_data.describe()\n",
    "training_test_data[['bc_up','bc_dn']].describe()\n",
    "# count = 4273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumRows_HeaderNo = len(training_test_data) = 4273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print training_test_data.head() # 1 row, 2+86 col\n",
    "# print training_test_data.tail() # 1 row, 2+86 col\n",
    "print 'NumRows_HeaderNo = len(training_test_data) = ' + str(len(training_test_data))\n",
    "\n",
    "# After noise removed\n",
    "# NumRows_HeaderNo = len(training_test_data) = 1430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 86 input columns\n",
    "predictors_tf = training_test_data[training_test_data.columns[4:]]\n",
    "# predictors_tf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 output columns\n",
    "# classes_tf = training_test_data[training_test_data.columns[:2]] # col 0, 1\n",
    "classes_tf = training_test_data[training_test_data.columns[2:4]] # col 2, 3\n",
    "# classes_tf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_size=3418\n",
      "test_set_size=855\n"
     ]
    }
   ],
   "source": [
    "# Split: train data = 80%\n",
    "training_set_size = int(len(training_test_data) * 0.8)\n",
    "print 'training_set_size=' + str(training_set_size )\n",
    "# Split: test data = 20%\n",
    "test_set_size = len(training_test_data) - training_set_size\n",
    "print 'test_set_size=' + str(test_set_size )\n",
    "\n",
    "# After noise removed\n",
    "# training_set_size=1144\n",
    "# test_set_size=286\n",
    "\n",
    "# stratification\n",
    "# training_set_size=3418\n",
    "# test_set_size=855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train: row 0 to 3417\n",
    "# input: cols 86\n",
    "training_predictors_tf = predictors_tf[:training_set_size]\n",
    "# print training_predictors_tf.head()\n",
    "# print training_predictors_tf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train: row 0 to 3417\n",
    "# output: cols 2\n",
    "training_classes_tf = classes_tf[:training_set_size]\n",
    "# print training_classes_tf.head()\n",
    "# print training_classes_tf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test: row 3418 to 4272 = new rows 0 to 854 = 855 test rows predictors\n",
    "# input: cols 86\n",
    "test_predictors_tf = predictors_tf[training_set_size:]\n",
    "# print test_predictors_tf.head()\n",
    "# print test_predictors_tf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test: row 3418 to 4272 = new rows 0 to 854 = 855 test rows classes\n",
    "# output: cols 2\n",
    "test_classes_tf = classes_tf[training_set_size:]\n",
    "# print test_classes_tf.head()\n",
    "# print test_classes_tf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train input\n",
    "# training_predictors_tf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test input\n",
    "# test_predictors_tf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some metrics here to evaluate the models.\n",
    "\n",
    "* [Precision](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) -  The ability of the classifier not to label as positive a sample that is negative.\n",
    "* [Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall) - The ability of the classifier to find all the positive samples.\n",
    "* [F1 Score](https://en.wikipedia.org/wiki/F1_score) - A weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "* Accuracy - The percentage correctly predicted in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_confusion_metrics(model, actual_classes, session, feed_dict):\n",
    "  predictions = tf.argmax(model, 1)\n",
    "  actuals = tf.argmax(actual_classes, 1)\n",
    "\n",
    "  ones_like_actuals = tf.ones_like(actuals)\n",
    "  zeros_like_actuals = tf.zeros_like(actuals)\n",
    "  ones_like_predictions = tf.ones_like(predictions)\n",
    "  zeros_like_predictions = tf.zeros_like(predictions)\n",
    "\n",
    "  tp_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, ones_like_actuals), \n",
    "        tf.equal(predictions, ones_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  tn_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, zeros_like_actuals), \n",
    "        tf.equal(predictions, zeros_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  fp_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, zeros_like_actuals), \n",
    "        tf.equal(predictions, ones_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  fn_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, ones_like_actuals), \n",
    "        tf.equal(predictions, zeros_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  tp, tn, fp, fn = \\\n",
    "    session.run(\n",
    "      [tp_op, tn_op, fp_op, fn_op], \n",
    "      feed_dict\n",
    "    )\n",
    "\n",
    "  tpr = float(tp)/(float(tp) + float(fn))\n",
    "  fpr = float(fp)/(float(tp) + float(fn))\n",
    "\n",
    "  accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))\n",
    "\n",
    "  recall = tpr\n",
    "  precision = float(tp)/(float(tp) + float(fp))\n",
    "  \n",
    "  f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "  \n",
    "  print 'Precision = ', precision\n",
    "  print 'Recall = ', recall\n",
    "  print 'F1 Score = ', f1_score\n",
    "  print 'Accuracy = ', accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get some tensors flowing. The model is binary classification expressed in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_predictors=148\n",
      "num_classes=2\n"
     ]
    }
   ],
   "source": [
    "# Define variables for the number of predictors and number of classes to remove magic numbers from our code.\n",
    "num_predictors = len(training_predictors_tf.columns) # 24-6=18 in the default case\n",
    "num_classes = len(training_classes_tf.columns) # 2 in the default case\n",
    "print 'num_predictors=' + str(num_predictors)\n",
    "print 'num_classes=' + str(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define placeholders for the data we feed into the process - feature data and actual classes.\n",
    "# input = 18\n",
    "feature_data = tf.placeholder(\"float\", [None, num_predictors])\n",
    "# output = 2\n",
    "actual_classes = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a matrix of weights and initialize it with some small random values.\n",
    "weights = tf.Variable(tf.truncated_normal([num_predictors, num_classes], stddev=0.0001))\n",
    "biases = tf.Variable(tf.ones([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define our model...\n",
    "# Here we take a softmax regression of the product of our feature data and weights.\n",
    "model = tf.nn.softmax(tf.matmul(feature_data, weights) + biases)\n",
    "\n",
    "# Define a cost function (we're using the cross entropy).\n",
    "cost = -tf.reduce_sum(actual_classes*tf.log(model))\n",
    "\n",
    "# Define a training step...\n",
    "# Here we use gradient descent with a learning rate of 0.01 using the cost function we just defined.\n",
    "training_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.63291785e-04  -1.66090074e-04]\n",
      " [ -4.33955465e-05  -4.52979439e-05]\n",
      " [ -2.21403297e-05  -1.28039581e-04]\n",
      " [  6.27423215e-05   9.38958037e-05]\n",
      " [  1.15476032e-04  -3.63204199e-05]\n",
      " [ -1.65383317e-05   9.16605859e-05]\n",
      " [ -2.00918639e-05  -1.58066832e-05]\n",
      " [  1.49539075e-04  -5.51692465e-05]\n",
      " [  4.92805702e-05   8.22446673e-05]\n",
      " [ -1.57276954e-04   5.10096434e-05]\n",
      " [ -1.92223320e-04  -8.03653456e-05]\n",
      " [ -6.37959374e-06  -4.13990847e-06]\n",
      " [ -1.19629520e-04  -1.07505126e-04]\n",
      " [ -1.19581040e-04   1.22839101e-05]\n",
      " [  1.06836451e-04   1.03199636e-04]\n",
      " [ -2.69036855e-06  -3.34675751e-05]\n",
      " [  1.34109767e-04   1.06049651e-04]\n",
      " [ -6.65966436e-05   1.52316925e-05]\n",
      " [ -1.02176222e-04  -2.53739890e-05]\n",
      " [  1.07935186e-04  -7.29370804e-05]\n",
      " [ -7.38700182e-05  -6.48156401e-06]\n",
      " [  1.51854605e-04   3.24675639e-05]\n",
      " [  5.63295180e-05   1.48884528e-05]\n",
      " [ -1.08504981e-04  -1.34578062e-04]\n",
      " [  7.13193658e-05   3.63923718e-05]\n",
      " [  3.38533682e-05  -1.72430286e-04]\n",
      " [ -1.48097039e-04   8.96250494e-05]\n",
      " [  8.17733162e-05   2.51565452e-05]\n",
      " [ -5.34480205e-05   1.03364990e-04]\n",
      " [  4.90897219e-06  -1.95015498e-04]\n",
      " [ -1.21989091e-04  -1.32155648e-04]\n",
      " [ -1.13673887e-04  -1.00649653e-04]\n",
      " [ -1.34808259e-04   9.37536970e-05]\n",
      " [ -1.13056660e-04  -1.74438392e-05]\n",
      " [ -1.64487195e-04  -9.89920522e-07]\n",
      " [ -1.21120338e-05   5.36671032e-05]\n",
      " [  5.50460754e-05   1.24914906e-04]\n",
      " [  1.96880646e-04  -1.59016941e-04]\n",
      " [ -6.16200050e-05  -1.21010577e-04]\n",
      " [  1.98019552e-04   7.64551150e-05]\n",
      " [  1.05953106e-04  -1.54968089e-04]\n",
      " [ -6.90566376e-05   4.42858400e-05]\n",
      " [  1.34109141e-04  -1.33216090e-04]\n",
      " [ -1.28696665e-05   1.38522846e-05]\n",
      " [  1.25234932e-04   2.83270710e-05]\n",
      " [ -2.71064964e-05  -6.11397772e-05]\n",
      " [  8.90934534e-05   1.44130114e-04]\n",
      " [ -7.92437859e-05  -6.47030902e-05]\n",
      " [  8.85072295e-05  -7.26242433e-05]\n",
      " [  1.40938035e-04  -5.59312284e-05]\n",
      " [ -2.87980965e-05   1.02367230e-04]\n",
      " [ -2.77957024e-05   4.71220337e-05]\n",
      " [  1.34982634e-04  -5.21438124e-05]\n",
      " [ -5.24409152e-05  -1.24796434e-05]\n",
      " [  1.26576910e-04   1.15501298e-05]\n",
      " [  2.98111013e-06  -9.97346870e-05]\n",
      " [ -7.23593184e-05   1.88454214e-05]\n",
      " [ -9.22920590e-05  -1.72936070e-05]\n",
      " [ -1.66535756e-04  -4.69660554e-05]\n",
      " [ -9.79986507e-05   1.24299395e-05]\n",
      " [ -4.31313892e-05  -8.73675308e-05]\n",
      " [ -1.86761812e-04   8.15903422e-06]\n",
      " [  5.21740913e-06   2.05224023e-05]\n",
      " [ -1.17414311e-05   7.90165723e-05]\n",
      " [  7.97176108e-05  -3.15569450e-05]\n",
      " [ -1.25842809e-04  -4.93085172e-05]\n",
      " [  1.42006931e-04   2.52102041e-06]\n",
      " [ -1.98947309e-04   1.18701857e-04]\n",
      " [  4.99113457e-06  -1.38831470e-04]\n",
      " [ -1.63884164e-04  -8.44655005e-05]\n",
      " [  1.00477046e-04  -3.01828550e-05]\n",
      " [  4.83020995e-05  -4.91658357e-05]\n",
      " [ -1.53836634e-04   5.39696375e-05]\n",
      " [  2.38094235e-05  -3.85312887e-05]\n",
      " [ -4.89652666e-05  -7.90368285e-05]\n",
      " [ -4.56344533e-05  -4.07721709e-05]\n",
      " [  2.34209365e-05   6.97458454e-05]\n",
      " [ -5.38171626e-05   2.99334406e-05]\n",
      " [  1.27375271e-04  -1.43864498e-04]\n",
      " [  1.47724199e-06  -7.95332089e-05]\n",
      " [ -5.41440058e-05  -8.08247278e-05]\n",
      " [ -2.71578447e-05   4.03899285e-05]\n",
      " [ -2.10209764e-05   1.51361077e-04]\n",
      " [  1.48144507e-04   3.71380993e-05]\n",
      " [  7.16093200e-05   1.17984819e-05]\n",
      " [ -1.27244799e-04  -9.79288816e-05]\n",
      " [ -1.16801690e-04  -2.62931899e-05]\n",
      " [ -3.79255434e-05   1.96545501e-04]\n",
      " [ -1.07871805e-04  -2.78692482e-06]\n",
      " [  1.63067103e-04   8.81372252e-05]\n",
      " [ -1.56445196e-04  -3.33248390e-05]\n",
      " [  1.31270805e-04  -1.87994228e-04]\n",
      " [ -1.11868212e-04  -6.86055064e-05]\n",
      " [  1.46782972e-04  -3.09264906e-05]\n",
      " [  9.14198390e-05  -1.96852216e-05]\n",
      " [ -7.13653280e-05  -7.31812033e-05]\n",
      " [ -2.35741550e-06   1.91133891e-04]\n",
      " [  1.41450582e-04   5.79504122e-05]\n",
      " [  9.92580317e-05  -9.83256759e-05]\n",
      " [ -5.32056620e-05  -5.11537473e-05]\n",
      " [  1.21792109e-04   4.35123802e-05]\n",
      " [  2.45666597e-05  -3.20910440e-05]\n",
      " [  3.05595422e-05  -3.11991789e-05]\n",
      " [  1.02639329e-04   1.12701498e-04]\n",
      " [  1.85967278e-04   4.08814230e-05]\n",
      " [ -1.55118469e-04   7.83054638e-05]\n",
      " [ -5.83673864e-05   2.96728595e-05]\n",
      " [ -2.35144635e-05  -1.20241690e-04]\n",
      " [  6.75015399e-05   5.99571467e-05]\n",
      " [  6.88475993e-05   9.58959299e-06]\n",
      " [  4.51198066e-05  -6.06252024e-06]\n",
      " [ -1.56614435e-04  -1.13845308e-04]\n",
      " [ -8.52791200e-05   7.31805776e-05]\n",
      " [  4.95811692e-05  -6.87604770e-05]\n",
      " [ -4.37764647e-05   5.41945919e-05]\n",
      " [  5.19308596e-05   5.70362026e-05]\n",
      " [ -7.72217900e-05  -2.49866735e-05]\n",
      " [ -1.11894471e-04  -1.31793186e-05]\n",
      " [ -9.86498053e-05  -3.98312477e-05]\n",
      " [  1.99858623e-04  -1.43836616e-04]\n",
      " [ -4.88714577e-05  -6.64589606e-05]\n",
      " [  1.02737868e-04   1.04221392e-04]\n",
      " [  1.19629920e-04   8.33420709e-05]\n",
      " [ -1.28711472e-05  -2.92591085e-05]\n",
      " [  8.34859020e-06   1.10134846e-04]\n",
      " [  4.09366803e-05   1.71605334e-05]\n",
      " [ -1.29128603e-05   1.36533810e-04]\n",
      " [  2.34034196e-05  -6.73634131e-05]\n",
      " [  1.23927921e-05  -6.72036913e-06]\n",
      " [  3.64981242e-05   3.76670869e-05]\n",
      " [  9.35335629e-06  -1.29456603e-04]\n",
      " [  5.22777736e-05  -3.99788696e-05]\n",
      " [ -1.64935846e-04   4.30133659e-05]\n",
      " [  3.71858732e-05   5.82019893e-05]\n",
      " [ -1.19186216e-05  -1.24401966e-04]\n",
      " [  9.49466121e-05  -4.99331436e-05]\n",
      " [ -5.61174129e-05  -1.52085224e-04]\n",
      " [  1.68616214e-04  -6.23907836e-05]\n",
      " [  8.82375098e-05   8.65704133e-05]\n",
      " [  6.82342943e-06  -2.25992139e-07]\n",
      " [ -1.32559901e-04   6.73007016e-05]\n",
      " [ -2.79039705e-05   9.06705682e-05]\n",
      " [  3.08588860e-05   9.84851431e-05]\n",
      " [ -5.46260817e-05   1.61085671e-04]\n",
      " [  7.96390377e-05  -2.99807980e-05]\n",
      " [ -4.73842811e-05   1.77778566e-04]\n",
      " [ -6.82405516e-06  -1.19270080e-04]\n",
      " [ -1.42112636e-04   9.28374211e-05]]\n"
     ]
    }
   ],
   "source": [
    "# BEFORE the model has been run, ie. not yet trained\n",
    "# display weights\n",
    "w_86_2 = sess.run(weights)    \n",
    "print w_86_2 \n",
    "\n",
    "# Expect something like this (small numbers e-05): \n",
    "# [[ -6.66152628e-05  -6.49469657e-05]\n",
    "#  [  2.86067752e-05   3.27789494e-05]\n",
    "#  [  4.73170294e-05   1.85125769e-04]\n",
    "#  [ -6.42955492e-05   4.16024632e-05]\n",
    "#  [ -1.54488771e-05  -2.10903818e-05]\n",
    "#  [  4.62506796e-05  -2.98624745e-05]\n",
    "#  [ -5.35508079e-05  -1.30856875e-04]\n",
    "#  [ -1.70812025e-04   1.33106529e-04]\n",
    "#  [ -1.45097118e-04  -1.80459567e-04]\n",
    "#  [  1.02448161e-04   8.27739277e-05]\n",
    "#  [ -1.33277281e-04  -4.04360726e-05]\n",
    "#  [ -1.36186543e-04   8.62382149e-05]\n",
    "#  [  2.80324894e-05  -2.20580205e-05]\n",
    "#  [ -4.52000713e-05   2.54859442e-05]\n",
    "#  [ -6.20259525e-05  -6.95227573e-05]\n",
    "#  [  1.68935469e-04  -4.03221093e-05]\n",
    "#  [ -9.51008842e-05   4.10227585e-05]\n",
    "#  [ -5.90909331e-05  -9.20566745e-05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train our model in the following snippet. The approach of TensorFlow to executing graph operations allows fine-grained control over the process. Any operation you provide to the session as part of the run operation will be executed and the results returned. You can provide a list of multiple operations.\n",
    "\n",
    "You'll train the model over 30,000 iterations using the full dataset each time. Every thousandth iteration we'll assess the accuracy of the model on the training data to assess progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 1.0\n",
      "10000 1.0\n",
      "15000 1.0\n",
      "20000 1.0\n",
      "25000 1.0\n",
      "30000 1.0\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(actual_classes, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "for i in range(1, 30001):\n",
    "  sess.run(\n",
    "    training_step, \n",
    "    feed_dict={\n",
    "      feature_data: training_predictors_tf.values, \n",
    "      actual_classes: training_classes_tf.values.reshape(len(training_classes_tf.values), 2)\n",
    "    }\n",
    "  )\n",
    "  if i%5000 == 0:\n",
    "    print i, sess.run(\n",
    "      accuracy,\n",
    "      feed_dict={\n",
    "        feature_data: training_predictors_tf.values, \n",
    "        actual_classes: training_classes_tf.values.reshape(len(training_classes_tf.values), 2)\n",
    "      }\n",
    "    )\n",
    "    \n",
    "# Expect:\n",
    "# 5000 0.603862\n",
    "# 10000 0.630778\n",
    "# 15000 0.639555\n",
    "# 20000 0.654184\n",
    "# 25000 0.660035\n",
    "# 30000 0.666764\n",
    "\n",
    "# After using < -0.5% and > +0.5%\n",
    "# 5000 0.928906\n",
    "# 10000 0.928906\n",
    "# 15000 0.928906\n",
    "# 20000 0.928906\n",
    "# 25000 0.928906\n",
    "# 30000 0.928906"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all data:\n",
    "Accuracy  66.6% on training data\n",
    "That is OK, better than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After noise removed, We get 77 % accuracy on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-53783f2ac90a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m }\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtf_confusion_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactual_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Precision =  0.541176470588\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-614b117b4e07>\u001b[0m in \u001b[0;36mtf_confusion_metrics\u001b[1;34m(model, actual_classes, session, feed_dict)\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m   \u001b[0mtpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[0mfpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "feed_dict= {\n",
    "  feature_data: test_predictors_tf.values,\n",
    "  actual_classes: test_classes_tf.values.reshape(len(test_classes_tf.values), 2)\n",
    "}\n",
    "\n",
    "tf_confusion_metrics(model, actual_classes, sess, feed_dict)\n",
    "\n",
    "# Precision =  0.541176470588\n",
    "# Recall =  0.555555555556\n",
    "# F1 Score =  0.548271752086\n",
    "# Accuracy =  0.556725146199\n",
    "\n",
    "# After removing noise\n",
    "# Precision =  0.684210526316\n",
    "# Recall =  0.534246575342\n",
    "# F1 Score =  0.6\n",
    "# Accuracy =  0.636363636364"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all data, Accuracy 55.6% on test data.\n",
    "After removing noise, Accuracy 64% on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "# display weights\n",
    "w_86_2 = sess.run(weights)    \n",
    "print w_86_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab a sample input row from the test set\n",
    "sample_input_1_86 = test_predictors_tf[:10]\n",
    "# HTML(pd.DataFrame(sample_input_1_86).to_html())\n",
    "sample_input_1_86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_input_1_86.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the weights from our model to make a prediction\n",
    "output_1_2 = np.dot(sample_input_1_86, w_86_2) > 0\n",
    "print output_1_2\n",
    "usdmxn_up = output_1_2[0,0]\n",
    "usdmxn_dn = output_1_2[0,1]\n",
    "if usdmxn_up >= usdmxn_dn:\n",
    "  usdmxn_pred = 1 # up\n",
    "else:\n",
    "  usdmxn_pred = -1 # down\n",
    "print 'usdmxn_pred = '+ str(usdmxn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Neural Network (NN): Feed-Forward with 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll now build a proper feed-forward neural net with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow session new\n",
    "sess1 = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "num_predictors = len(training_predictors_tf.columns)\n",
    "print 'num_predictors=' + str(num_predictors)\n",
    "\n",
    "# outputs\n",
    "num_classes = len(training_classes_tf.columns)\n",
    "print 'num_classes=' + str(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_data = tf.placeholder(\"float\", [None, num_predictors])\n",
    "actual_classes = tf.placeholder(\"float\", [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layer 1\n",
    "i_01_in = 86\n",
    "i_01_out = 100\n",
    "weights1 = tf.Variable(tf.truncated_normal([i_01_in, i_01_out], stddev=0.0001))\n",
    "biases1 = tf.Variable(tf.ones([i_01_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer 2\n",
    "i_02_in = i_01_out\n",
    "i_02_out = 25\n",
    "weights2 = tf.Variable(tf.truncated_normal([i_02_in, i_02_out], stddev=0.0001))\n",
    "biases2 = tf.Variable(tf.ones([i_02_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer 3\n",
    "i_03_in = i_02_out\n",
    "i_03_out = 2\n",
    "weights3 = tf.Variable(tf.truncated_normal([i_03_in, i_03_out], stddev=0.0001))\n",
    "biases3 = tf.Variable(tf.ones([i_03_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neural net\n",
    "hidden_layer_0 = feature_data\n",
    "hidden_layer_1 = tf.nn.relu(tf.matmul(hidden_layer_0, weights1) + biases1)\n",
    "hidden_layer_2 = tf.nn.relu(tf.matmul(hidden_layer_1, weights2) + biases2)\n",
    "hidden_layer_3 = tf.matmul(hidden_layer_2, weights3) + biases3\n",
    "\n",
    "model = tf.nn.softmax(hidden_layer_3)\n",
    "\n",
    "cost = -tf.reduce_sum(actual_classes*tf.log(model))\n",
    "\n",
    "train_op1 = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess1.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "nn_e1 = sess1.run(biases1)    \n",
    "# HTML(pd.DataFrame(nn_e1).transpose().to_html())\n",
    "pd.DataFrame(nn_e1).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "nn_w1 = sess1.run(weights1)    \n",
    "# HTML(pd.DataFrame(nn_w1).to_html())\n",
    "pd.DataFrame(nn_w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "nn_e2 = sess1.run(biases2)    \n",
    "# HTML(pd.DataFrame(nn_e2).transpose().to_html())\n",
    "pd.DataFrame(nn_e2).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "# display weights\n",
    "nn_w2 = sess1.run(weights2)    \n",
    "# HTML(pd.DataFrame(nn_w2).to_html())\n",
    "pd.DataFrame(nn_w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "nn_e3 = sess1.run(biases3)    \n",
    "# HTML(pd.DataFrame(nn_e3).transpose().to_html())\n",
    "pd.DataFrame(nn_e3).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEFORE the model has been run, ie. trained\n",
    "# display weights\n",
    "nn_w3 = sess1.run(weights3)    \n",
    "# HTML(pd.DataFrame(nn_w3).to_html())\n",
    "pd.DataFrame(nn_w3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you'll train the model over 10,000 iterations using the full dataset each time. Every thousandth iteration, you'll assess the accuracy of the model on the training data to assess progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(actual_classes, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "num_iterations = 10001\n",
    "num_iterations_until_diaplay = 1000\n",
    "\n",
    "for i in range(1, num_iterations):\n",
    "  sess1.run(\n",
    "    train_op1, \n",
    "    feed_dict={\n",
    "      feature_data: training_predictors_tf.values, \n",
    "      actual_classes: training_classes_tf.values.reshape(len(training_classes_tf.values), 2)\n",
    "    }\n",
    "  )\n",
    "  if i%num_iterations_until_diaplay == 0:\n",
    "    print i, sess1.run(\n",
    "      accuracy,\n",
    "      feed_dict={\n",
    "        feature_data: training_predictors_tf.values, \n",
    "        actual_classes: training_classes_tf.values.reshape(len(training_classes_tf.values), 2)\n",
    "      }\n",
    "    )\n",
    "  \n",
    "  \n",
    "  \n",
    "# 1000 0.67086\n",
    "# 2000 0.765652\n",
    "# 3000 0.828847\n",
    "# 4000 0.890287\n",
    "# 5000 0.937975\n",
    "# 6000 0.956115\n",
    "# 7000 0.971913\n",
    "# 8000 0.979813\n",
    "# 9000 0.985079\n",
    "# 10000 0.987712\n",
    "\n",
    "# 5000 0.93505\n",
    "# 10000 0.988297\n",
    "# 15000 0.491223 # overfit?\n",
    "# 20000 0.491223\n",
    "# 25000 0.491223\n",
    "# 30000 0.491223\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant improvement in accuracy with the training data shows that the hidden layers are adding additional capacity for learning to the model.\n",
    "\n",
    "Looking at precision, recall, and accuracy, you can see a measurable improvement in performance, but certainly not a [step function](https://wikipedia.org/wiki/Step_function). This indicates that we're likely reaching the limits of this relatively simple feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict= {\n",
    "  feature_data: test_predictors_tf.values,\n",
    "  actual_classes: test_classes_tf.values.reshape(len(test_classes_tf.values), 2)\n",
    "}\n",
    "\n",
    "tf_confusion_metrics(model, actual_classes, sess1, feed_dict)\n",
    "\n",
    "# Precision =  0.936768149883\n",
    "# Recall =  0.966183574879\n",
    "# F1 Score =  0.951248513674\n",
    "# Accuracy =  0.952046783626\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "nn_e1 = sess1.run(biases1)    \n",
    "# HTML(pd.DataFrame(nn_e1).transpose().to_html())\n",
    "pd.DataFrame(nn_e1).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "# display weights\n",
    "nn_w1 = sess1.run(weights1)    \n",
    "# HTML(pd.DataFrame(nn_w1).to_html())\n",
    "pd.DataFrame(nn_w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "nn_e2 = sess1.run(biases2)    \n",
    "# HTML(pd.DataFrame(nn_e2).transpose().to_html())\n",
    "pd.DataFrame(nn_e2).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "# display weights\n",
    "nn_w2 = sess1.run(weights2)    \n",
    "# HTML(pd.DataFrame(nn_w2).to_html())\n",
    "pd.DataFrame(nn_w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "nn_e3 = sess1.run(biases3)    \n",
    "# HTML(pd.DataFrame(nn_e3).transpose().to_html())\n",
    "pd.DataFrame(nn_e3).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AFTER the model has been run, ie. trained\n",
    "# display weights\n",
    "nn_w3 = sess1.run(weights3)    \n",
    "# HTML(pd.DataFrame(nn_w3).to_html())\n",
    "pd.DataFrame(nn_w3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # AFTER the model has been run, ie. trained\n",
    "# nn_hl3 = sess1.run(hidden_layer_3)    \n",
    "# print nn_hl3\n",
    "# # HTML(pd.DataFrame(nn_hl3).to_html())\n",
    "# pd.DataFrame(nn_hl3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've covered a lot of ground. You moved from sourcing five years of financial time-series data, to munging that data into a more suitable form. You explored and visualized that data with exploratory data analysis and then decided on a machine learning model and the features for that model. You engineered those features, built a binary classifier in TensorFlow, and analyzed its performance. You built a feed forward neural net with two hidden layers in TensorFlow and analyzed its performance.\n",
    "\n",
    "How did the technology fare? It should take most people 1.5 to 3 hours to extract the juice from this solution, and none of that time is spent waiting for infrastructure or software; it's spent reading and thinking. In many organizations, it can take anywhere from days to months to do this sort of data analysis, depending on whether you need to procure any hardware. And you didn't need to do anything with infrastructure or additional software. Rather, you used a web-based console to direct GCP to set up systems on your behalf, which it did—fully managed, maintained, and supported—freeing you up to spend your time analyzing. \n",
    "\n",
    "It was also cost effective. If you took your time with this solution and spent three hours to go through it, the cost would be a few pennies. \n",
    "\n",
    "Cloud Datalab worked admirably, too. iPython/Jupyter has always been a great platform for interactive, iterative work and a fully-managed version of that platform on GCP, with connectors to other GCP technologies such as BigQuery and Google Cloud Storage, is a force multiplier for your analysis needs.  If you haven't used iPython before, this solution might have been eye opening, for you. If you're already familiar with iPython, then you'll love the connectors to other GCP technologies.\n",
    "\n",
    "Of course, R and Matlab are popular tools in machine learning, and we've made no mention either in this solution. Neither R nor Matlab are available as managed services on GCP. Both can be hosted in GCP and accessed through a cloud-friendly, web frontend.\n",
    "\n",
    "TensorFlow is a special piece of technology. It is expressive, performs well, and comes with the weight of Google's machine learning history and expertise to back it up and support it. We've only scratched the surface, but you can already see that within a handful of lines of code we've been able to write two models. Neither of them is cutting edge, by design, but neither of them is trivial either. With some additional tuning they would suit a whole spectrum of machine learning tasks. \n",
    "\n",
    "Finally, how did we do with the data analysis? We did well: over 70% accuracy in predicting the close of the S&P 500 is the highest we've seen achieved on this dataset, so with few steps and a few lines of code we've produced a full-on machine learning model. The reason for the relatively modest accuracy achieved is the dataset itself; there isn't enough signal there to do significantly better. But 7 times out of 10, we were able to correctly determine if the S&P 500 index would close up or down on the day, and that's objectively good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you're finished, shut down the managed VM you used for Cloud Datalab to avoid incurring costs.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
